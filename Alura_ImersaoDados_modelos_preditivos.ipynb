{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alura_ImersaoDados_modelos_preditivos",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS6sZcTaggJ0"
      },
      "source": [
        "# Nos capítulos anteriores..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXVW8xhRYkWI"
      },
      "source": [
        "No primeiro arquivo fizemos uma análise exploratória dos dados dos experimentos e no segundo arquivo, analizamos os dados dos resultados dos experimentos. Está na hora e juntarmos esses dois conjutos de dados e utilizarmos técnicas de machine learning para tentar fazer preivisões de problemas. \n",
        "Mas antes, precisamos carregar novamente os bancos de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaqDwN4BgpJH"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') #ignora as mensagens de aviso"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqeZ9QFZgtmW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "h7I_N9NRg0mu",
        "outputId": "5e111e4b-0f84-42bf-d04c-e9a087f63024"
      },
      "source": [
        "url_dados = 'https://github.com/alura-cursos/imersaodados3/blob/main/dados/dados_experimentos.zip?raw=true'\n",
        "df = pd.read_csv(url_dados, compression = 'zip')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tratamento</th>\n",
              "      <th>tempo</th>\n",
              "      <th>dose</th>\n",
              "      <th>droga</th>\n",
              "      <th>g-0</th>\n",
              "      <th>g-1</th>\n",
              "      <th>g-2</th>\n",
              "      <th>g-3</th>\n",
              "      <th>g-4</th>\n",
              "      <th>g-5</th>\n",
              "      <th>g-6</th>\n",
              "      <th>g-7</th>\n",
              "      <th>g-8</th>\n",
              "      <th>g-9</th>\n",
              "      <th>g-10</th>\n",
              "      <th>g-11</th>\n",
              "      <th>g-12</th>\n",
              "      <th>g-13</th>\n",
              "      <th>g-14</th>\n",
              "      <th>g-15</th>\n",
              "      <th>g-16</th>\n",
              "      <th>g-17</th>\n",
              "      <th>g-18</th>\n",
              "      <th>g-19</th>\n",
              "      <th>g-20</th>\n",
              "      <th>g-21</th>\n",
              "      <th>g-22</th>\n",
              "      <th>g-23</th>\n",
              "      <th>g-24</th>\n",
              "      <th>g-25</th>\n",
              "      <th>g-26</th>\n",
              "      <th>g-27</th>\n",
              "      <th>g-28</th>\n",
              "      <th>g-29</th>\n",
              "      <th>g-30</th>\n",
              "      <th>g-31</th>\n",
              "      <th>g-32</th>\n",
              "      <th>g-33</th>\n",
              "      <th>g-34</th>\n",
              "      <th>...</th>\n",
              "      <th>c-60</th>\n",
              "      <th>c-61</th>\n",
              "      <th>c-62</th>\n",
              "      <th>c-63</th>\n",
              "      <th>c-64</th>\n",
              "      <th>c-65</th>\n",
              "      <th>c-66</th>\n",
              "      <th>c-67</th>\n",
              "      <th>c-68</th>\n",
              "      <th>c-69</th>\n",
              "      <th>c-70</th>\n",
              "      <th>c-71</th>\n",
              "      <th>c-72</th>\n",
              "      <th>c-73</th>\n",
              "      <th>c-74</th>\n",
              "      <th>c-75</th>\n",
              "      <th>c-76</th>\n",
              "      <th>c-77</th>\n",
              "      <th>c-78</th>\n",
              "      <th>c-79</th>\n",
              "      <th>c-80</th>\n",
              "      <th>c-81</th>\n",
              "      <th>c-82</th>\n",
              "      <th>c-83</th>\n",
              "      <th>c-84</th>\n",
              "      <th>c-85</th>\n",
              "      <th>c-86</th>\n",
              "      <th>c-87</th>\n",
              "      <th>c-88</th>\n",
              "      <th>c-89</th>\n",
              "      <th>c-90</th>\n",
              "      <th>c-91</th>\n",
              "      <th>c-92</th>\n",
              "      <th>c-93</th>\n",
              "      <th>c-94</th>\n",
              "      <th>c-95</th>\n",
              "      <th>c-96</th>\n",
              "      <th>c-97</th>\n",
              "      <th>c-98</th>\n",
              "      <th>c-99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D1</td>\n",
              "      <td>b68db1d53</td>\n",
              "      <td>1.0620</td>\n",
              "      <td>0.5577</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-0.6208</td>\n",
              "      <td>-0.1944</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>-1.0220</td>\n",
              "      <td>-0.0326</td>\n",
              "      <td>0.5548</td>\n",
              "      <td>-0.0921</td>\n",
              "      <td>1.1830</td>\n",
              "      <td>0.1530</td>\n",
              "      <td>0.5574</td>\n",
              "      <td>-0.4015</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>-0.6528</td>\n",
              "      <td>-0.7969</td>\n",
              "      <td>0.6342</td>\n",
              "      <td>0.1778</td>\n",
              "      <td>-0.3694</td>\n",
              "      <td>-0.5688</td>\n",
              "      <td>-1.1360</td>\n",
              "      <td>-1.1880</td>\n",
              "      <td>0.6940</td>\n",
              "      <td>0.4393</td>\n",
              "      <td>0.2664</td>\n",
              "      <td>0.1907</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>-0.2853</td>\n",
              "      <td>0.5819</td>\n",
              "      <td>0.2934</td>\n",
              "      <td>-0.5584</td>\n",
              "      <td>-0.0916</td>\n",
              "      <td>-0.3010</td>\n",
              "      <td>-0.1537</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4805</td>\n",
              "      <td>0.4965</td>\n",
              "      <td>0.3680</td>\n",
              "      <td>0.8427</td>\n",
              "      <td>0.1042</td>\n",
              "      <td>0.1403</td>\n",
              "      <td>0.1758</td>\n",
              "      <td>1.2570</td>\n",
              "      <td>-0.5979</td>\n",
              "      <td>1.2250</td>\n",
              "      <td>-0.0553</td>\n",
              "      <td>0.7351</td>\n",
              "      <td>0.5810</td>\n",
              "      <td>0.9590</td>\n",
              "      <td>0.2427</td>\n",
              "      <td>0.0495</td>\n",
              "      <td>0.4141</td>\n",
              "      <td>0.8432</td>\n",
              "      <td>0.6162</td>\n",
              "      <td>-0.7318</td>\n",
              "      <td>1.2120</td>\n",
              "      <td>0.6362</td>\n",
              "      <td>-0.4427</td>\n",
              "      <td>0.1288</td>\n",
              "      <td>1.4840</td>\n",
              "      <td>0.1799</td>\n",
              "      <td>0.5367</td>\n",
              "      <td>-0.1111</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>0.6685</td>\n",
              "      <td>0.2862</td>\n",
              "      <td>0.2584</td>\n",
              "      <td>0.8076</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.1912</td>\n",
              "      <td>0.6584</td>\n",
              "      <td>-0.3981</td>\n",
              "      <td>0.2139</td>\n",
              "      <td>0.3801</td>\n",
              "      <td>0.4176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D1</td>\n",
              "      <td>df89a8e5a</td>\n",
              "      <td>0.0743</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.2991</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>1.0190</td>\n",
              "      <td>0.5207</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.3372</td>\n",
              "      <td>-0.4047</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>-1.1520</td>\n",
              "      <td>-0.4201</td>\n",
              "      <td>-0.0958</td>\n",
              "      <td>0.4590</td>\n",
              "      <td>0.0803</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>0.5293</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>-0.3494</td>\n",
              "      <td>0.2883</td>\n",
              "      <td>0.9449</td>\n",
              "      <td>-0.1646</td>\n",
              "      <td>-0.2657</td>\n",
              "      <td>-0.3372</td>\n",
              "      <td>0.3135</td>\n",
              "      <td>-0.4316</td>\n",
              "      <td>0.4773</td>\n",
              "      <td>0.2075</td>\n",
              "      <td>-0.4216</td>\n",
              "      <td>-0.1161</td>\n",
              "      <td>-0.0499</td>\n",
              "      <td>-0.2627</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>-0.2483</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4083</td>\n",
              "      <td>0.0319</td>\n",
              "      <td>0.3905</td>\n",
              "      <td>0.7099</td>\n",
              "      <td>0.2912</td>\n",
              "      <td>0.4151</td>\n",
              "      <td>-0.2840</td>\n",
              "      <td>-0.3104</td>\n",
              "      <td>-0.6373</td>\n",
              "      <td>0.2887</td>\n",
              "      <td>-0.0765</td>\n",
              "      <td>0.2539</td>\n",
              "      <td>0.4443</td>\n",
              "      <td>0.5932</td>\n",
              "      <td>0.2031</td>\n",
              "      <td>0.7639</td>\n",
              "      <td>0.5499</td>\n",
              "      <td>-0.3322</td>\n",
              "      <td>-0.0977</td>\n",
              "      <td>0.4329</td>\n",
              "      <td>-0.2782</td>\n",
              "      <td>0.7827</td>\n",
              "      <td>0.5934</td>\n",
              "      <td>0.3402</td>\n",
              "      <td>0.1499</td>\n",
              "      <td>0.4420</td>\n",
              "      <td>0.9366</td>\n",
              "      <td>0.8193</td>\n",
              "      <td>-0.4236</td>\n",
              "      <td>0.3192</td>\n",
              "      <td>-0.4265</td>\n",
              "      <td>0.7543</td>\n",
              "      <td>0.4708</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.2957</td>\n",
              "      <td>0.4899</td>\n",
              "      <td>0.1522</td>\n",
              "      <td>0.1241</td>\n",
              "      <td>0.6077</td>\n",
              "      <td>0.7371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>18bb41b2c</td>\n",
              "      <td>0.6280</td>\n",
              "      <td>0.5817</td>\n",
              "      <td>1.5540</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.0323</td>\n",
              "      <td>1.2390</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>-0.4797</td>\n",
              "      <td>-0.5631</td>\n",
              "      <td>-0.0366</td>\n",
              "      <td>-1.8300</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>-0.3278</td>\n",
              "      <td>0.6042</td>\n",
              "      <td>-0.3075</td>\n",
              "      <td>-0.1147</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>-0.0799</td>\n",
              "      <td>-0.8181</td>\n",
              "      <td>-1.5320</td>\n",
              "      <td>0.2307</td>\n",
              "      <td>0.4901</td>\n",
              "      <td>0.4780</td>\n",
              "      <td>-1.3970</td>\n",
              "      <td>4.6240</td>\n",
              "      <td>-0.0437</td>\n",
              "      <td>1.2870</td>\n",
              "      <td>-1.8530</td>\n",
              "      <td>0.6069</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>0.1783</td>\n",
              "      <td>0.0018</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.5477</td>\n",
              "      <td>-0.7576</td>\n",
              "      <td>-0.0444</td>\n",
              "      <td>0.1894</td>\n",
              "      <td>-0.0014</td>\n",
              "      <td>-2.3640</td>\n",
              "      <td>-0.4682</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>-0.5177</td>\n",
              "      <td>-0.0604</td>\n",
              "      <td>0.1682</td>\n",
              "      <td>-0.4436</td>\n",
              "      <td>0.4963</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.9760</td>\n",
              "      <td>-0.0427</td>\n",
              "      <td>-0.1235</td>\n",
              "      <td>0.0959</td>\n",
              "      <td>0.0690</td>\n",
              "      <td>-0.9416</td>\n",
              "      <td>-0.7548</td>\n",
              "      <td>-0.1109</td>\n",
              "      <td>-0.6272</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>0.1172</td>\n",
              "      <td>0.1093</td>\n",
              "      <td>-0.3113</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>-0.0873</td>\n",
              "      <td>-0.7250</td>\n",
              "      <td>-0.6297</td>\n",
              "      <td>0.6103</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>-1.3240</td>\n",
              "      <td>-0.3174</td>\n",
              "      <td>-0.6417</td>\n",
              "      <td>-0.2187</td>\n",
              "      <td>-1.4080</td>\n",
              "      <td>0.6931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>8c7f86626</td>\n",
              "      <td>-0.5138</td>\n",
              "      <td>-0.2491</td>\n",
              "      <td>-0.2656</td>\n",
              "      <td>0.5288</td>\n",
              "      <td>4.0620</td>\n",
              "      <td>-0.8095</td>\n",
              "      <td>-1.9590</td>\n",
              "      <td>0.1792</td>\n",
              "      <td>-0.1321</td>\n",
              "      <td>-1.0600</td>\n",
              "      <td>-0.8269</td>\n",
              "      <td>-0.3584</td>\n",
              "      <td>-0.8511</td>\n",
              "      <td>-0.5844</td>\n",
              "      <td>-2.5690</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>-0.0532</td>\n",
              "      <td>-0.8554</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>-2.3520</td>\n",
              "      <td>2.1200</td>\n",
              "      <td>-1.1580</td>\n",
              "      <td>-0.7191</td>\n",
              "      <td>-0.8004</td>\n",
              "      <td>-1.4670</td>\n",
              "      <td>-0.0107</td>\n",
              "      <td>-0.8995</td>\n",
              "      <td>0.2406</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-1.0890</td>\n",
              "      <td>-0.7575</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>-2.7370</td>\n",
              "      <td>0.8745</td>\n",
              "      <td>0.5787</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.1220</td>\n",
              "      <td>-0.3752</td>\n",
              "      <td>-2.3820</td>\n",
              "      <td>-3.7350</td>\n",
              "      <td>-2.9740</td>\n",
              "      <td>-1.4930</td>\n",
              "      <td>-1.6600</td>\n",
              "      <td>-3.1660</td>\n",
              "      <td>0.2816</td>\n",
              "      <td>-0.2990</td>\n",
              "      <td>-1.1870</td>\n",
              "      <td>-0.5044</td>\n",
              "      <td>-1.7750</td>\n",
              "      <td>-1.6120</td>\n",
              "      <td>-0.9215</td>\n",
              "      <td>-1.0810</td>\n",
              "      <td>-3.0520</td>\n",
              "      <td>-3.4470</td>\n",
              "      <td>-2.7740</td>\n",
              "      <td>-1.8460</td>\n",
              "      <td>-0.5568</td>\n",
              "      <td>-3.3960</td>\n",
              "      <td>-2.9510</td>\n",
              "      <td>-1.1550</td>\n",
              "      <td>-3.2620</td>\n",
              "      <td>-1.5390</td>\n",
              "      <td>-2.4600</td>\n",
              "      <td>-0.9417</td>\n",
              "      <td>-1.5550</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>-2.0990</td>\n",
              "      <td>-0.6441</td>\n",
              "      <td>-5.6300</td>\n",
              "      <td>-1.3780</td>\n",
              "      <td>-0.8632</td>\n",
              "      <td>-1.2880</td>\n",
              "      <td>-1.6210</td>\n",
              "      <td>-0.8784</td>\n",
              "      <td>-0.3876</td>\n",
              "      <td>-0.8154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D2</td>\n",
              "      <td>7cbed3131</td>\n",
              "      <td>-0.3254</td>\n",
              "      <td>-0.4009</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>1.4180</td>\n",
              "      <td>-0.8244</td>\n",
              "      <td>-0.2800</td>\n",
              "      <td>-0.1498</td>\n",
              "      <td>-0.8789</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>-0.5121</td>\n",
              "      <td>-0.9577</td>\n",
              "      <td>1.1750</td>\n",
              "      <td>0.2042</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1244</td>\n",
              "      <td>-1.7090</td>\n",
              "      <td>-0.3543</td>\n",
              "      <td>-0.5160</td>\n",
              "      <td>-0.3330</td>\n",
              "      <td>-0.2685</td>\n",
              "      <td>0.7649</td>\n",
              "      <td>0.2057</td>\n",
              "      <td>1.3720</td>\n",
              "      <td>0.6835</td>\n",
              "      <td>0.8056</td>\n",
              "      <td>-0.3754</td>\n",
              "      <td>-1.2090</td>\n",
              "      <td>0.2965</td>\n",
              "      <td>-0.0712</td>\n",
              "      <td>0.6389</td>\n",
              "      <td>0.6674</td>\n",
              "      <td>-0.0783</td>\n",
              "      <td>1.1740</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.2274</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1535</td>\n",
              "      <td>-0.4640</td>\n",
              "      <td>-0.5943</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>0.5159</td>\n",
              "      <td>0.6091</td>\n",
              "      <td>0.1813</td>\n",
              "      <td>-0.4249</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>0.5648</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.0587</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.6376</td>\n",
              "      <td>-0.3966</td>\n",
              "      <td>-1.4950</td>\n",
              "      <td>-0.9625</td>\n",
              "      <td>-0.0541</td>\n",
              "      <td>0.6273</td>\n",
              "      <td>0.4563</td>\n",
              "      <td>0.0698</td>\n",
              "      <td>0.8134</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.6054</td>\n",
              "      <td>-0.1824</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.6670</td>\n",
              "      <td>1.0690</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.3031</td>\n",
              "      <td>0.1094</td>\n",
              "      <td>0.2885</td>\n",
              "      <td>-0.3786</td>\n",
              "      <td>0.7125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 877 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id tratamento  tempo dose  ...    c-96    c-97    c-98    c-99\n",
              "0  id_000644bb2  com_droga     24   D1  ... -0.3981  0.2139  0.3801  0.4176\n",
              "1  id_000779bfc  com_droga     72   D1  ...  0.1522  0.1241  0.6077  0.7371\n",
              "2  id_000a6266a  com_droga     48   D1  ... -0.6417 -0.2187 -1.4080  0.6931\n",
              "3  id_0015fd391  com_droga     48   D1  ... -1.6210 -0.8784 -0.3876 -0.8154\n",
              "4  id_001626bd3  com_droga     72   D2  ...  0.1094  0.2885 -0.3786  0.7125\n",
              "\n",
              "[5 rows x 877 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "Q8Q-t2f_g52E",
        "outputId": "260810f5-df44-4875-d33f-8ee3b1d3217f"
      },
      "source": [
        "#Renomeando as colunas, eliminando '-'\n",
        "colunas = df.columns.to_numpy()  #cria um array com os nomes das colunas\n",
        "for i in range(0,colunas.shape[0]):\n",
        "   colunas[i] = colunas[i].replace('-','')  #faz um loop percorrendo os índices do array, trocando '-' por ''\n",
        "df.columns = colunas  #renomeia as colunas\n",
        "df.rename(columns= {'droga':'composto'}, inplace = True) #renomeia a coluna 'droga' para 'composto'\n",
        "df.tail() #mostra os 5 últimos regristos"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tratamento</th>\n",
              "      <th>tempo</th>\n",
              "      <th>dose</th>\n",
              "      <th>composto</th>\n",
              "      <th>g0</th>\n",
              "      <th>g1</th>\n",
              "      <th>g2</th>\n",
              "      <th>g3</th>\n",
              "      <th>g4</th>\n",
              "      <th>g5</th>\n",
              "      <th>g6</th>\n",
              "      <th>g7</th>\n",
              "      <th>g8</th>\n",
              "      <th>g9</th>\n",
              "      <th>g10</th>\n",
              "      <th>g11</th>\n",
              "      <th>g12</th>\n",
              "      <th>g13</th>\n",
              "      <th>g14</th>\n",
              "      <th>g15</th>\n",
              "      <th>g16</th>\n",
              "      <th>g17</th>\n",
              "      <th>g18</th>\n",
              "      <th>g19</th>\n",
              "      <th>g20</th>\n",
              "      <th>g21</th>\n",
              "      <th>g22</th>\n",
              "      <th>g23</th>\n",
              "      <th>g24</th>\n",
              "      <th>g25</th>\n",
              "      <th>g26</th>\n",
              "      <th>g27</th>\n",
              "      <th>g28</th>\n",
              "      <th>g29</th>\n",
              "      <th>g30</th>\n",
              "      <th>g31</th>\n",
              "      <th>g32</th>\n",
              "      <th>g33</th>\n",
              "      <th>g34</th>\n",
              "      <th>...</th>\n",
              "      <th>c60</th>\n",
              "      <th>c61</th>\n",
              "      <th>c62</th>\n",
              "      <th>c63</th>\n",
              "      <th>c64</th>\n",
              "      <th>c65</th>\n",
              "      <th>c66</th>\n",
              "      <th>c67</th>\n",
              "      <th>c68</th>\n",
              "      <th>c69</th>\n",
              "      <th>c70</th>\n",
              "      <th>c71</th>\n",
              "      <th>c72</th>\n",
              "      <th>c73</th>\n",
              "      <th>c74</th>\n",
              "      <th>c75</th>\n",
              "      <th>c76</th>\n",
              "      <th>c77</th>\n",
              "      <th>c78</th>\n",
              "      <th>c79</th>\n",
              "      <th>c80</th>\n",
              "      <th>c81</th>\n",
              "      <th>c82</th>\n",
              "      <th>c83</th>\n",
              "      <th>c84</th>\n",
              "      <th>c85</th>\n",
              "      <th>c86</th>\n",
              "      <th>c87</th>\n",
              "      <th>c88</th>\n",
              "      <th>c89</th>\n",
              "      <th>c90</th>\n",
              "      <th>c91</th>\n",
              "      <th>c92</th>\n",
              "      <th>c93</th>\n",
              "      <th>c94</th>\n",
              "      <th>c95</th>\n",
              "      <th>c96</th>\n",
              "      <th>c97</th>\n",
              "      <th>c98</th>\n",
              "      <th>c99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23809</th>\n",
              "      <td>id_fffb1ceed</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D2</td>\n",
              "      <td>df1d0a5a1</td>\n",
              "      <td>0.1394</td>\n",
              "      <td>-0.0636</td>\n",
              "      <td>-0.1112</td>\n",
              "      <td>-0.5080</td>\n",
              "      <td>-0.4713</td>\n",
              "      <td>0.7201</td>\n",
              "      <td>0.5773</td>\n",
              "      <td>0.3055</td>\n",
              "      <td>-0.4726</td>\n",
              "      <td>0.1269</td>\n",
              "      <td>0.2531</td>\n",
              "      <td>0.1730</td>\n",
              "      <td>-0.4532</td>\n",
              "      <td>-1.0790</td>\n",
              "      <td>0.2474</td>\n",
              "      <td>-0.4550</td>\n",
              "      <td>0.3588</td>\n",
              "      <td>0.1600</td>\n",
              "      <td>-0.7362</td>\n",
              "      <td>-0.1103</td>\n",
              "      <td>0.8550</td>\n",
              "      <td>-0.4139</td>\n",
              "      <td>0.5541</td>\n",
              "      <td>0.2310</td>\n",
              "      <td>-0.5573</td>\n",
              "      <td>-0.4397</td>\n",
              "      <td>-0.9260</td>\n",
              "      <td>-0.2424</td>\n",
              "      <td>-0.6686</td>\n",
              "      <td>0.2326</td>\n",
              "      <td>0.6456</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>-0.5141</td>\n",
              "      <td>-0.6320</td>\n",
              "      <td>0.7166</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0807</td>\n",
              "      <td>0.4024</td>\n",
              "      <td>-0.0895</td>\n",
              "      <td>0.4420</td>\n",
              "      <td>0.9641</td>\n",
              "      <td>-0.1846</td>\n",
              "      <td>-0.0014</td>\n",
              "      <td>0.3154</td>\n",
              "      <td>-0.2071</td>\n",
              "      <td>-0.6158</td>\n",
              "      <td>-0.2977</td>\n",
              "      <td>0.0992</td>\n",
              "      <td>0.6838</td>\n",
              "      <td>0.5259</td>\n",
              "      <td>0.7882</td>\n",
              "      <td>0.3119</td>\n",
              "      <td>-0.7697</td>\n",
              "      <td>0.2203</td>\n",
              "      <td>-1.0710</td>\n",
              "      <td>0.5979</td>\n",
              "      <td>0.0848</td>\n",
              "      <td>-0.2555</td>\n",
              "      <td>0.6293</td>\n",
              "      <td>1.1660</td>\n",
              "      <td>0.3329</td>\n",
              "      <td>0.2754</td>\n",
              "      <td>0.4108</td>\n",
              "      <td>-0.1252</td>\n",
              "      <td>-0.2340</td>\n",
              "      <td>0.2267</td>\n",
              "      <td>0.1969</td>\n",
              "      <td>0.0262</td>\n",
              "      <td>-0.8121</td>\n",
              "      <td>0.3434</td>\n",
              "      <td>0.5372</td>\n",
              "      <td>-0.3246</td>\n",
              "      <td>0.0631</td>\n",
              "      <td>0.9171</td>\n",
              "      <td>0.5258</td>\n",
              "      <td>0.4680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23810</th>\n",
              "      <td>id_fffb70c0c</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D2</td>\n",
              "      <td>ecf3b6b74</td>\n",
              "      <td>-1.3260</td>\n",
              "      <td>0.3478</td>\n",
              "      <td>-0.3743</td>\n",
              "      <td>0.9905</td>\n",
              "      <td>-0.7178</td>\n",
              "      <td>0.6621</td>\n",
              "      <td>-0.2252</td>\n",
              "      <td>-0.5565</td>\n",
              "      <td>0.5112</td>\n",
              "      <td>0.6727</td>\n",
              "      <td>-0.1851</td>\n",
              "      <td>2.8650</td>\n",
              "      <td>-0.2140</td>\n",
              "      <td>-0.6153</td>\n",
              "      <td>0.8362</td>\n",
              "      <td>0.5584</td>\n",
              "      <td>-0.2589</td>\n",
              "      <td>0.1292</td>\n",
              "      <td>0.0148</td>\n",
              "      <td>0.0949</td>\n",
              "      <td>-0.2182</td>\n",
              "      <td>-0.9235</td>\n",
              "      <td>0.0749</td>\n",
              "      <td>-1.5910</td>\n",
              "      <td>-0.8359</td>\n",
              "      <td>-0.9217</td>\n",
              "      <td>0.3013</td>\n",
              "      <td>0.1716</td>\n",
              "      <td>0.0880</td>\n",
              "      <td>0.1842</td>\n",
              "      <td>0.1835</td>\n",
              "      <td>0.5436</td>\n",
              "      <td>-0.0533</td>\n",
              "      <td>-0.0491</td>\n",
              "      <td>0.9543</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>1.2640</td>\n",
              "      <td>-0.8663</td>\n",
              "      <td>0.8129</td>\n",
              "      <td>-0.1514</td>\n",
              "      <td>-0.4652</td>\n",
              "      <td>-0.7390</td>\n",
              "      <td>-1.3270</td>\n",
              "      <td>0.9925</td>\n",
              "      <td>1.0570</td>\n",
              "      <td>-0.3355</td>\n",
              "      <td>-0.2555</td>\n",
              "      <td>0.8219</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>-0.2942</td>\n",
              "      <td>0.2408</td>\n",
              "      <td>-0.7781</td>\n",
              "      <td>-0.0929</td>\n",
              "      <td>-0.0329</td>\n",
              "      <td>0.0781</td>\n",
              "      <td>-1.4440</td>\n",
              "      <td>-0.0921</td>\n",
              "      <td>0.3188</td>\n",
              "      <td>-1.1080</td>\n",
              "      <td>0.4895</td>\n",
              "      <td>-0.2144</td>\n",
              "      <td>1.0960</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>-1.1130</td>\n",
              "      <td>0.4286</td>\n",
              "      <td>0.4426</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>-0.3195</td>\n",
              "      <td>-0.8086</td>\n",
              "      <td>-0.9798</td>\n",
              "      <td>-0.2084</td>\n",
              "      <td>-0.1224</td>\n",
              "      <td>-0.2715</td>\n",
              "      <td>0.3689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23811</th>\n",
              "      <td>id_fffc1c3f4</td>\n",
              "      <td>com_controle</td>\n",
              "      <td>48</td>\n",
              "      <td>D2</td>\n",
              "      <td>cacb2b860</td>\n",
              "      <td>0.3942</td>\n",
              "      <td>0.3756</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>-0.7389</td>\n",
              "      <td>0.5505</td>\n",
              "      <td>-0.0159</td>\n",
              "      <td>-0.2541</td>\n",
              "      <td>0.1745</td>\n",
              "      <td>-0.0340</td>\n",
              "      <td>0.4865</td>\n",
              "      <td>-0.1854</td>\n",
              "      <td>0.0716</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>-0.0434</td>\n",
              "      <td>0.1542</td>\n",
              "      <td>-0.2192</td>\n",
              "      <td>-0.0302</td>\n",
              "      <td>-0.4218</td>\n",
              "      <td>0.4057</td>\n",
              "      <td>-0.5372</td>\n",
              "      <td>0.1521</td>\n",
              "      <td>-0.2651</td>\n",
              "      <td>0.2310</td>\n",
              "      <td>-0.8101</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.6905</td>\n",
              "      <td>-0.3720</td>\n",
              "      <td>-1.4110</td>\n",
              "      <td>0.4516</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>-0.1949</td>\n",
              "      <td>-1.3280</td>\n",
              "      <td>-0.4276</td>\n",
              "      <td>-0.0040</td>\n",
              "      <td>-0.3086</td>\n",
              "      <td>...</td>\n",
              "      <td>0.6845</td>\n",
              "      <td>0.7127</td>\n",
              "      <td>0.7294</td>\n",
              "      <td>0.4718</td>\n",
              "      <td>-0.2020</td>\n",
              "      <td>0.2783</td>\n",
              "      <td>0.4934</td>\n",
              "      <td>0.4144</td>\n",
              "      <td>0.5449</td>\n",
              "      <td>1.4690</td>\n",
              "      <td>-0.6142</td>\n",
              "      <td>0.6068</td>\n",
              "      <td>0.3434</td>\n",
              "      <td>0.9880</td>\n",
              "      <td>-0.0468</td>\n",
              "      <td>-0.1882</td>\n",
              "      <td>-0.0087</td>\n",
              "      <td>-0.0356</td>\n",
              "      <td>0.5718</td>\n",
              "      <td>0.4971</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.6992</td>\n",
              "      <td>0.0708</td>\n",
              "      <td>0.6169</td>\n",
              "      <td>0.2248</td>\n",
              "      <td>0.5994</td>\n",
              "      <td>0.2689</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>1.2320</td>\n",
              "      <td>0.5409</td>\n",
              "      <td>0.3755</td>\n",
              "      <td>0.7343</td>\n",
              "      <td>0.2807</td>\n",
              "      <td>0.4116</td>\n",
              "      <td>0.6422</td>\n",
              "      <td>0.2256</td>\n",
              "      <td>0.7592</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.3808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23812</th>\n",
              "      <td>id_fffcb9e7c</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D1</td>\n",
              "      <td>8b87a7a83</td>\n",
              "      <td>0.6660</td>\n",
              "      <td>0.2324</td>\n",
              "      <td>0.4392</td>\n",
              "      <td>0.2044</td>\n",
              "      <td>0.8531</td>\n",
              "      <td>-0.0343</td>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.0463</td>\n",
              "      <td>0.4299</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>0.5742</td>\n",
              "      <td>0.1421</td>\n",
              "      <td>2.2700</td>\n",
              "      <td>0.2046</td>\n",
              "      <td>0.5363</td>\n",
              "      <td>-1.7330</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.2024</td>\n",
              "      <td>0.9865</td>\n",
              "      <td>-0.7805</td>\n",
              "      <td>0.9608</td>\n",
              "      <td>0.3440</td>\n",
              "      <td>2.7650</td>\n",
              "      <td>0.4925</td>\n",
              "      <td>0.6698</td>\n",
              "      <td>0.2374</td>\n",
              "      <td>-0.3372</td>\n",
              "      <td>0.8771</td>\n",
              "      <td>-2.6560</td>\n",
              "      <td>-0.2000</td>\n",
              "      <td>-0.2043</td>\n",
              "      <td>0.6797</td>\n",
              "      <td>-0.0248</td>\n",
              "      <td>-0.0927</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3360</td>\n",
              "      <td>-0.6136</td>\n",
              "      <td>0.5011</td>\n",
              "      <td>0.9261</td>\n",
              "      <td>0.4419</td>\n",
              "      <td>0.0295</td>\n",
              "      <td>0.4220</td>\n",
              "      <td>0.4677</td>\n",
              "      <td>-0.1184</td>\n",
              "      <td>0.4524</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.1356</td>\n",
              "      <td>-0.5801</td>\n",
              "      <td>0.0411</td>\n",
              "      <td>1.0240</td>\n",
              "      <td>1.0340</td>\n",
              "      <td>-0.0270</td>\n",
              "      <td>-0.4194</td>\n",
              "      <td>0.7403</td>\n",
              "      <td>-0.6793</td>\n",
              "      <td>-0.1423</td>\n",
              "      <td>0.7307</td>\n",
              "      <td>0.7946</td>\n",
              "      <td>-0.0650</td>\n",
              "      <td>0.9038</td>\n",
              "      <td>0.2324</td>\n",
              "      <td>0.9676</td>\n",
              "      <td>1.0940</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>0.5187</td>\n",
              "      <td>-0.1105</td>\n",
              "      <td>0.4258</td>\n",
              "      <td>-0.2012</td>\n",
              "      <td>0.1506</td>\n",
              "      <td>1.5230</td>\n",
              "      <td>0.7101</td>\n",
              "      <td>0.1732</td>\n",
              "      <td>0.7015</td>\n",
              "      <td>-0.6290</td>\n",
              "      <td>0.0740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23813</th>\n",
              "      <td>id_ffffdd77b</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D1</td>\n",
              "      <td>972f41291</td>\n",
              "      <td>-0.8598</td>\n",
              "      <td>1.0240</td>\n",
              "      <td>-0.1361</td>\n",
              "      <td>0.7952</td>\n",
              "      <td>-0.3611</td>\n",
              "      <td>-3.6750</td>\n",
              "      <td>-1.2420</td>\n",
              "      <td>0.9146</td>\n",
              "      <td>3.0790</td>\n",
              "      <td>1.2460</td>\n",
              "      <td>1.9460</td>\n",
              "      <td>1.4370</td>\n",
              "      <td>2.9780</td>\n",
              "      <td>2.2370</td>\n",
              "      <td>-0.6818</td>\n",
              "      <td>0.6870</td>\n",
              "      <td>-1.1060</td>\n",
              "      <td>0.0182</td>\n",
              "      <td>-0.9247</td>\n",
              "      <td>-0.0738</td>\n",
              "      <td>-0.1919</td>\n",
              "      <td>-0.7722</td>\n",
              "      <td>-1.4050</td>\n",
              "      <td>-1.0050</td>\n",
              "      <td>-1.1170</td>\n",
              "      <td>-0.5293</td>\n",
              "      <td>-1.1720</td>\n",
              "      <td>-0.2885</td>\n",
              "      <td>0.1599</td>\n",
              "      <td>-0.4250</td>\n",
              "      <td>0.3591</td>\n",
              "      <td>-0.1420</td>\n",
              "      <td>-0.9530</td>\n",
              "      <td>-0.2005</td>\n",
              "      <td>-1.8340</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.9170</td>\n",
              "      <td>-1.8640</td>\n",
              "      <td>-2.5090</td>\n",
              "      <td>-4.7130</td>\n",
              "      <td>-1.7250</td>\n",
              "      <td>-3.8650</td>\n",
              "      <td>-3.0800</td>\n",
              "      <td>-4.1530</td>\n",
              "      <td>-1.2030</td>\n",
              "      <td>-1.1690</td>\n",
              "      <td>-4.1460</td>\n",
              "      <td>-1.2670</td>\n",
              "      <td>-1.1300</td>\n",
              "      <td>-2.4390</td>\n",
              "      <td>0.1591</td>\n",
              "      <td>-2.2490</td>\n",
              "      <td>-2.5860</td>\n",
              "      <td>-1.9520</td>\n",
              "      <td>-2.1810</td>\n",
              "      <td>-4.6690</td>\n",
              "      <td>-3.9450</td>\n",
              "      <td>-2.9560</td>\n",
              "      <td>-2.7930</td>\n",
              "      <td>-2.1560</td>\n",
              "      <td>-2.4100</td>\n",
              "      <td>-1.8190</td>\n",
              "      <td>-3.3480</td>\n",
              "      <td>-0.1414</td>\n",
              "      <td>-2.6430</td>\n",
              "      <td>-2.5810</td>\n",
              "      <td>-3.3890</td>\n",
              "      <td>-1.7450</td>\n",
              "      <td>-6.6300</td>\n",
              "      <td>-4.0950</td>\n",
              "      <td>-7.3860</td>\n",
              "      <td>-1.4160</td>\n",
              "      <td>-3.5770</td>\n",
              "      <td>-0.4775</td>\n",
              "      <td>-2.1500</td>\n",
              "      <td>-4.2520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 877 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id    tratamento  tempo dose  ...     c96     c97     c98     c99\n",
              "23809  id_fffb1ceed     com_droga     24   D2  ...  0.0631  0.9171  0.5258  0.4680\n",
              "23810  id_fffb70c0c     com_droga     24   D2  ... -0.2084 -0.1224 -0.2715  0.3689\n",
              "23811  id_fffc1c3f4  com_controle     48   D2  ...  0.2256  0.7592  0.6656  0.3808\n",
              "23812  id_fffcb9e7c     com_droga     24   D1  ...  0.1732  0.7015 -0.6290  0.0740\n",
              "23813  id_ffffdd77b     com_droga     72   D1  ... -3.5770 -0.4775 -2.1500 -4.2520\n",
              "\n",
              "[5 rows x 877 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "kygfpnBvhBfz",
        "outputId": "b6864262-807c-4b89-d77f-fa80a099fd1b"
      },
      "source": [
        "df_resultados = pd.read_csv('https://github.com/alura-cursos/imersaodados3/blob/main/dados/dados_resultados.csv?raw=true')\n",
        "df_resultados"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>5-alpha_reductase_inhibitor</th>\n",
              "      <th>11-beta-hsd1_inhibitor</th>\n",
              "      <th>acat_inhibitor</th>\n",
              "      <th>acetylcholine_receptor_agonist</th>\n",
              "      <th>acetylcholine_receptor_antagonist</th>\n",
              "      <th>acetylcholinesterase_inhibitor</th>\n",
              "      <th>adenosine_receptor_agonist</th>\n",
              "      <th>adenosine_receptor_antagonist</th>\n",
              "      <th>adenylyl_cyclase_activator</th>\n",
              "      <th>adrenergic_receptor_agonist</th>\n",
              "      <th>adrenergic_receptor_antagonist</th>\n",
              "      <th>akt_inhibitor</th>\n",
              "      <th>aldehyde_dehydrogenase_inhibitor</th>\n",
              "      <th>alk_inhibitor</th>\n",
              "      <th>ampk_activator</th>\n",
              "      <th>analgesic</th>\n",
              "      <th>androgen_receptor_agonist</th>\n",
              "      <th>androgen_receptor_antagonist</th>\n",
              "      <th>anesthetic_-_local</th>\n",
              "      <th>angiogenesis_inhibitor</th>\n",
              "      <th>angiotensin_receptor_antagonist</th>\n",
              "      <th>anti-inflammatory</th>\n",
              "      <th>antiarrhythmic</th>\n",
              "      <th>antibiotic</th>\n",
              "      <th>anticonvulsant</th>\n",
              "      <th>antifungal</th>\n",
              "      <th>antihistamine</th>\n",
              "      <th>antimalarial</th>\n",
              "      <th>antioxidant</th>\n",
              "      <th>antiprotozoal</th>\n",
              "      <th>antiviral</th>\n",
              "      <th>apoptosis_stimulant</th>\n",
              "      <th>aromatase_inhibitor</th>\n",
              "      <th>atm_kinase_inhibitor</th>\n",
              "      <th>atp-sensitive_potassium_channel_antagonist</th>\n",
              "      <th>atp_synthase_inhibitor</th>\n",
              "      <th>atpase_inhibitor</th>\n",
              "      <th>atr_kinase_inhibitor</th>\n",
              "      <th>aurora_kinase_inhibitor</th>\n",
              "      <th>...</th>\n",
              "      <th>protein_synthesis_inhibitor</th>\n",
              "      <th>protein_tyrosine_kinase_inhibitor</th>\n",
              "      <th>radiopaque_medium</th>\n",
              "      <th>raf_inhibitor</th>\n",
              "      <th>ras_gtpase_inhibitor</th>\n",
              "      <th>retinoid_receptor_agonist</th>\n",
              "      <th>retinoid_receptor_antagonist</th>\n",
              "      <th>rho_associated_kinase_inhibitor</th>\n",
              "      <th>ribonucleoside_reductase_inhibitor</th>\n",
              "      <th>rna_polymerase_inhibitor</th>\n",
              "      <th>serotonin_receptor_agonist</th>\n",
              "      <th>serotonin_receptor_antagonist</th>\n",
              "      <th>serotonin_reuptake_inhibitor</th>\n",
              "      <th>sigma_receptor_agonist</th>\n",
              "      <th>sigma_receptor_antagonist</th>\n",
              "      <th>smoothened_receptor_antagonist</th>\n",
              "      <th>sodium_channel_inhibitor</th>\n",
              "      <th>sphingosine_receptor_agonist</th>\n",
              "      <th>src_inhibitor</th>\n",
              "      <th>steroid</th>\n",
              "      <th>syk_inhibitor</th>\n",
              "      <th>tachykinin_antagonist</th>\n",
              "      <th>tgf-beta_receptor_inhibitor</th>\n",
              "      <th>thrombin_inhibitor</th>\n",
              "      <th>thymidylate_synthase_inhibitor</th>\n",
              "      <th>tlr_agonist</th>\n",
              "      <th>tlr_antagonist</th>\n",
              "      <th>tnf_inhibitor</th>\n",
              "      <th>topoisomerase_inhibitor</th>\n",
              "      <th>transient_receptor_potential_channel_antagonist</th>\n",
              "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
              "      <th>trpv_agonist</th>\n",
              "      <th>trpv_antagonist</th>\n",
              "      <th>tubulin_inhibitor</th>\n",
              "      <th>tyrosine_kinase_inhibitor</th>\n",
              "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
              "      <th>vegfr_inhibitor</th>\n",
              "      <th>vitamin_b</th>\n",
              "      <th>vitamin_d_receptor_agonist</th>\n",
              "      <th>wnt_inhibitor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23809</th>\n",
              "      <td>id_fffb1ceed</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23810</th>\n",
              "      <td>id_fffb70c0c</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23811</th>\n",
              "      <td>id_fffc1c3f4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23812</th>\n",
              "      <td>id_fffcb9e7c</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23813</th>\n",
              "      <td>id_ffffdd77b</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23814 rows × 207 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...  wnt_inhibitor\n",
              "0      id_000644bb2  ...              0\n",
              "1      id_000779bfc  ...              0\n",
              "2      id_000a6266a  ...              0\n",
              "3      id_0015fd391  ...              0\n",
              "4      id_001626bd3  ...              0\n",
              "...             ...  ...            ...\n",
              "23809  id_fffb1ceed  ...              0\n",
              "23810  id_fffb70c0c  ...              0\n",
              "23811  id_fffc1c3f4  ...              0\n",
              "23812  id_fffcb9e7c  ...              0\n",
              "23813  id_ffffdd77b  ...              0\n",
              "\n",
              "[23814 rows x 207 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqIGYoJ2hH_1"
      },
      "source": [
        "df_resultados['n_moa'] = df_resultados.drop('id', axis=1).sum(axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "xkJ6jk75hLP_",
        "outputId": "e7b24734-a06f-4886-fca6-552928b8f18f"
      },
      "source": [
        "df_resultados['ativo_moa'] = (df_resultados['n_moa'] != 0)*1\n",
        "df_resultados.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>5-alpha_reductase_inhibitor</th>\n",
              "      <th>11-beta-hsd1_inhibitor</th>\n",
              "      <th>acat_inhibitor</th>\n",
              "      <th>acetylcholine_receptor_agonist</th>\n",
              "      <th>acetylcholine_receptor_antagonist</th>\n",
              "      <th>acetylcholinesterase_inhibitor</th>\n",
              "      <th>adenosine_receptor_agonist</th>\n",
              "      <th>adenosine_receptor_antagonist</th>\n",
              "      <th>adenylyl_cyclase_activator</th>\n",
              "      <th>adrenergic_receptor_agonist</th>\n",
              "      <th>adrenergic_receptor_antagonist</th>\n",
              "      <th>akt_inhibitor</th>\n",
              "      <th>aldehyde_dehydrogenase_inhibitor</th>\n",
              "      <th>alk_inhibitor</th>\n",
              "      <th>ampk_activator</th>\n",
              "      <th>analgesic</th>\n",
              "      <th>androgen_receptor_agonist</th>\n",
              "      <th>androgen_receptor_antagonist</th>\n",
              "      <th>anesthetic_-_local</th>\n",
              "      <th>angiogenesis_inhibitor</th>\n",
              "      <th>angiotensin_receptor_antagonist</th>\n",
              "      <th>anti-inflammatory</th>\n",
              "      <th>antiarrhythmic</th>\n",
              "      <th>antibiotic</th>\n",
              "      <th>anticonvulsant</th>\n",
              "      <th>antifungal</th>\n",
              "      <th>antihistamine</th>\n",
              "      <th>antimalarial</th>\n",
              "      <th>antioxidant</th>\n",
              "      <th>antiprotozoal</th>\n",
              "      <th>antiviral</th>\n",
              "      <th>apoptosis_stimulant</th>\n",
              "      <th>aromatase_inhibitor</th>\n",
              "      <th>atm_kinase_inhibitor</th>\n",
              "      <th>atp-sensitive_potassium_channel_antagonist</th>\n",
              "      <th>atp_synthase_inhibitor</th>\n",
              "      <th>atpase_inhibitor</th>\n",
              "      <th>atr_kinase_inhibitor</th>\n",
              "      <th>aurora_kinase_inhibitor</th>\n",
              "      <th>...</th>\n",
              "      <th>radiopaque_medium</th>\n",
              "      <th>raf_inhibitor</th>\n",
              "      <th>ras_gtpase_inhibitor</th>\n",
              "      <th>retinoid_receptor_agonist</th>\n",
              "      <th>retinoid_receptor_antagonist</th>\n",
              "      <th>rho_associated_kinase_inhibitor</th>\n",
              "      <th>ribonucleoside_reductase_inhibitor</th>\n",
              "      <th>rna_polymerase_inhibitor</th>\n",
              "      <th>serotonin_receptor_agonist</th>\n",
              "      <th>serotonin_receptor_antagonist</th>\n",
              "      <th>serotonin_reuptake_inhibitor</th>\n",
              "      <th>sigma_receptor_agonist</th>\n",
              "      <th>sigma_receptor_antagonist</th>\n",
              "      <th>smoothened_receptor_antagonist</th>\n",
              "      <th>sodium_channel_inhibitor</th>\n",
              "      <th>sphingosine_receptor_agonist</th>\n",
              "      <th>src_inhibitor</th>\n",
              "      <th>steroid</th>\n",
              "      <th>syk_inhibitor</th>\n",
              "      <th>tachykinin_antagonist</th>\n",
              "      <th>tgf-beta_receptor_inhibitor</th>\n",
              "      <th>thrombin_inhibitor</th>\n",
              "      <th>thymidylate_synthase_inhibitor</th>\n",
              "      <th>tlr_agonist</th>\n",
              "      <th>tlr_antagonist</th>\n",
              "      <th>tnf_inhibitor</th>\n",
              "      <th>topoisomerase_inhibitor</th>\n",
              "      <th>transient_receptor_potential_channel_antagonist</th>\n",
              "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
              "      <th>trpv_agonist</th>\n",
              "      <th>trpv_antagonist</th>\n",
              "      <th>tubulin_inhibitor</th>\n",
              "      <th>tyrosine_kinase_inhibitor</th>\n",
              "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
              "      <th>vegfr_inhibitor</th>\n",
              "      <th>vitamin_b</th>\n",
              "      <th>vitamin_d_receptor_agonist</th>\n",
              "      <th>wnt_inhibitor</th>\n",
              "      <th>n_moa</th>\n",
              "      <th>ativo_moa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 209 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  5-alpha_reductase_inhibitor  ...  n_moa  ativo_moa\n",
              "0  id_000644bb2                            0  ...      1          1\n",
              "1  id_000779bfc                            0  ...      0          0\n",
              "2  id_000a6266a                            0  ...      3          1\n",
              "3  id_0015fd391                            0  ...      0          0\n",
              "4  id_001626bd3                            0  ...      1          1\n",
              "\n",
              "[5 rows x 209 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "TOdNXvOAhOmt",
        "outputId": "81987e7b-29e5-412e-e92f-a506ed57abe9"
      },
      "source": [
        "df_total = pd.merge(df, df_resultados[['id','n_moa', 'ativo_moa']], on='id')\n",
        "df_total.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tratamento</th>\n",
              "      <th>tempo</th>\n",
              "      <th>dose</th>\n",
              "      <th>composto</th>\n",
              "      <th>g0</th>\n",
              "      <th>g1</th>\n",
              "      <th>g2</th>\n",
              "      <th>g3</th>\n",
              "      <th>g4</th>\n",
              "      <th>g5</th>\n",
              "      <th>g6</th>\n",
              "      <th>g7</th>\n",
              "      <th>g8</th>\n",
              "      <th>g9</th>\n",
              "      <th>g10</th>\n",
              "      <th>g11</th>\n",
              "      <th>g12</th>\n",
              "      <th>g13</th>\n",
              "      <th>g14</th>\n",
              "      <th>g15</th>\n",
              "      <th>g16</th>\n",
              "      <th>g17</th>\n",
              "      <th>g18</th>\n",
              "      <th>g19</th>\n",
              "      <th>g20</th>\n",
              "      <th>g21</th>\n",
              "      <th>g22</th>\n",
              "      <th>g23</th>\n",
              "      <th>g24</th>\n",
              "      <th>g25</th>\n",
              "      <th>g26</th>\n",
              "      <th>g27</th>\n",
              "      <th>g28</th>\n",
              "      <th>g29</th>\n",
              "      <th>g30</th>\n",
              "      <th>g31</th>\n",
              "      <th>g32</th>\n",
              "      <th>g33</th>\n",
              "      <th>g34</th>\n",
              "      <th>...</th>\n",
              "      <th>c62</th>\n",
              "      <th>c63</th>\n",
              "      <th>c64</th>\n",
              "      <th>c65</th>\n",
              "      <th>c66</th>\n",
              "      <th>c67</th>\n",
              "      <th>c68</th>\n",
              "      <th>c69</th>\n",
              "      <th>c70</th>\n",
              "      <th>c71</th>\n",
              "      <th>c72</th>\n",
              "      <th>c73</th>\n",
              "      <th>c74</th>\n",
              "      <th>c75</th>\n",
              "      <th>c76</th>\n",
              "      <th>c77</th>\n",
              "      <th>c78</th>\n",
              "      <th>c79</th>\n",
              "      <th>c80</th>\n",
              "      <th>c81</th>\n",
              "      <th>c82</th>\n",
              "      <th>c83</th>\n",
              "      <th>c84</th>\n",
              "      <th>c85</th>\n",
              "      <th>c86</th>\n",
              "      <th>c87</th>\n",
              "      <th>c88</th>\n",
              "      <th>c89</th>\n",
              "      <th>c90</th>\n",
              "      <th>c91</th>\n",
              "      <th>c92</th>\n",
              "      <th>c93</th>\n",
              "      <th>c94</th>\n",
              "      <th>c95</th>\n",
              "      <th>c96</th>\n",
              "      <th>c97</th>\n",
              "      <th>c98</th>\n",
              "      <th>c99</th>\n",
              "      <th>n_moa</th>\n",
              "      <th>ativo_moa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D1</td>\n",
              "      <td>b68db1d53</td>\n",
              "      <td>1.0620</td>\n",
              "      <td>0.5577</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-0.6208</td>\n",
              "      <td>-0.1944</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>-1.0220</td>\n",
              "      <td>-0.0326</td>\n",
              "      <td>0.5548</td>\n",
              "      <td>-0.0921</td>\n",
              "      <td>1.1830</td>\n",
              "      <td>0.1530</td>\n",
              "      <td>0.5574</td>\n",
              "      <td>-0.4015</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>-0.6528</td>\n",
              "      <td>-0.7969</td>\n",
              "      <td>0.6342</td>\n",
              "      <td>0.1778</td>\n",
              "      <td>-0.3694</td>\n",
              "      <td>-0.5688</td>\n",
              "      <td>-1.1360</td>\n",
              "      <td>-1.1880</td>\n",
              "      <td>0.6940</td>\n",
              "      <td>0.4393</td>\n",
              "      <td>0.2664</td>\n",
              "      <td>0.1907</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>-0.2853</td>\n",
              "      <td>0.5819</td>\n",
              "      <td>0.2934</td>\n",
              "      <td>-0.5584</td>\n",
              "      <td>-0.0916</td>\n",
              "      <td>-0.3010</td>\n",
              "      <td>-0.1537</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3680</td>\n",
              "      <td>0.8427</td>\n",
              "      <td>0.1042</td>\n",
              "      <td>0.1403</td>\n",
              "      <td>0.1758</td>\n",
              "      <td>1.2570</td>\n",
              "      <td>-0.5979</td>\n",
              "      <td>1.2250</td>\n",
              "      <td>-0.0553</td>\n",
              "      <td>0.7351</td>\n",
              "      <td>0.5810</td>\n",
              "      <td>0.9590</td>\n",
              "      <td>0.2427</td>\n",
              "      <td>0.0495</td>\n",
              "      <td>0.4141</td>\n",
              "      <td>0.8432</td>\n",
              "      <td>0.6162</td>\n",
              "      <td>-0.7318</td>\n",
              "      <td>1.2120</td>\n",
              "      <td>0.6362</td>\n",
              "      <td>-0.4427</td>\n",
              "      <td>0.1288</td>\n",
              "      <td>1.4840</td>\n",
              "      <td>0.1799</td>\n",
              "      <td>0.5367</td>\n",
              "      <td>-0.1111</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>0.6685</td>\n",
              "      <td>0.2862</td>\n",
              "      <td>0.2584</td>\n",
              "      <td>0.8076</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.1912</td>\n",
              "      <td>0.6584</td>\n",
              "      <td>-0.3981</td>\n",
              "      <td>0.2139</td>\n",
              "      <td>0.3801</td>\n",
              "      <td>0.4176</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D1</td>\n",
              "      <td>df89a8e5a</td>\n",
              "      <td>0.0743</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.2991</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>1.0190</td>\n",
              "      <td>0.5207</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.3372</td>\n",
              "      <td>-0.4047</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>-1.1520</td>\n",
              "      <td>-0.4201</td>\n",
              "      <td>-0.0958</td>\n",
              "      <td>0.4590</td>\n",
              "      <td>0.0803</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>0.5293</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>-0.3494</td>\n",
              "      <td>0.2883</td>\n",
              "      <td>0.9449</td>\n",
              "      <td>-0.1646</td>\n",
              "      <td>-0.2657</td>\n",
              "      <td>-0.3372</td>\n",
              "      <td>0.3135</td>\n",
              "      <td>-0.4316</td>\n",
              "      <td>0.4773</td>\n",
              "      <td>0.2075</td>\n",
              "      <td>-0.4216</td>\n",
              "      <td>-0.1161</td>\n",
              "      <td>-0.0499</td>\n",
              "      <td>-0.2627</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>-0.2483</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3905</td>\n",
              "      <td>0.7099</td>\n",
              "      <td>0.2912</td>\n",
              "      <td>0.4151</td>\n",
              "      <td>-0.2840</td>\n",
              "      <td>-0.3104</td>\n",
              "      <td>-0.6373</td>\n",
              "      <td>0.2887</td>\n",
              "      <td>-0.0765</td>\n",
              "      <td>0.2539</td>\n",
              "      <td>0.4443</td>\n",
              "      <td>0.5932</td>\n",
              "      <td>0.2031</td>\n",
              "      <td>0.7639</td>\n",
              "      <td>0.5499</td>\n",
              "      <td>-0.3322</td>\n",
              "      <td>-0.0977</td>\n",
              "      <td>0.4329</td>\n",
              "      <td>-0.2782</td>\n",
              "      <td>0.7827</td>\n",
              "      <td>0.5934</td>\n",
              "      <td>0.3402</td>\n",
              "      <td>0.1499</td>\n",
              "      <td>0.4420</td>\n",
              "      <td>0.9366</td>\n",
              "      <td>0.8193</td>\n",
              "      <td>-0.4236</td>\n",
              "      <td>0.3192</td>\n",
              "      <td>-0.4265</td>\n",
              "      <td>0.7543</td>\n",
              "      <td>0.4708</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.2957</td>\n",
              "      <td>0.4899</td>\n",
              "      <td>0.1522</td>\n",
              "      <td>0.1241</td>\n",
              "      <td>0.6077</td>\n",
              "      <td>0.7371</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>18bb41b2c</td>\n",
              "      <td>0.6280</td>\n",
              "      <td>0.5817</td>\n",
              "      <td>1.5540</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.0323</td>\n",
              "      <td>1.2390</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>-0.4797</td>\n",
              "      <td>-0.5631</td>\n",
              "      <td>-0.0366</td>\n",
              "      <td>-1.8300</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>-0.3278</td>\n",
              "      <td>0.6042</td>\n",
              "      <td>-0.3075</td>\n",
              "      <td>-0.1147</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>-0.0799</td>\n",
              "      <td>-0.8181</td>\n",
              "      <td>-1.5320</td>\n",
              "      <td>0.2307</td>\n",
              "      <td>0.4901</td>\n",
              "      <td>0.4780</td>\n",
              "      <td>-1.3970</td>\n",
              "      <td>4.6240</td>\n",
              "      <td>-0.0437</td>\n",
              "      <td>1.2870</td>\n",
              "      <td>-1.8530</td>\n",
              "      <td>0.6069</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>0.1783</td>\n",
              "      <td>0.0018</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0444</td>\n",
              "      <td>0.1894</td>\n",
              "      <td>-0.0014</td>\n",
              "      <td>-2.3640</td>\n",
              "      <td>-0.4682</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>-0.5177</td>\n",
              "      <td>-0.0604</td>\n",
              "      <td>0.1682</td>\n",
              "      <td>-0.4436</td>\n",
              "      <td>0.4963</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.9760</td>\n",
              "      <td>-0.0427</td>\n",
              "      <td>-0.1235</td>\n",
              "      <td>0.0959</td>\n",
              "      <td>0.0690</td>\n",
              "      <td>-0.9416</td>\n",
              "      <td>-0.7548</td>\n",
              "      <td>-0.1109</td>\n",
              "      <td>-0.6272</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>0.1172</td>\n",
              "      <td>0.1093</td>\n",
              "      <td>-0.3113</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>-0.0873</td>\n",
              "      <td>-0.7250</td>\n",
              "      <td>-0.6297</td>\n",
              "      <td>0.6103</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>-1.3240</td>\n",
              "      <td>-0.3174</td>\n",
              "      <td>-0.6417</td>\n",
              "      <td>-0.2187</td>\n",
              "      <td>-1.4080</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>8c7f86626</td>\n",
              "      <td>-0.5138</td>\n",
              "      <td>-0.2491</td>\n",
              "      <td>-0.2656</td>\n",
              "      <td>0.5288</td>\n",
              "      <td>4.0620</td>\n",
              "      <td>-0.8095</td>\n",
              "      <td>-1.9590</td>\n",
              "      <td>0.1792</td>\n",
              "      <td>-0.1321</td>\n",
              "      <td>-1.0600</td>\n",
              "      <td>-0.8269</td>\n",
              "      <td>-0.3584</td>\n",
              "      <td>-0.8511</td>\n",
              "      <td>-0.5844</td>\n",
              "      <td>-2.5690</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>-0.0532</td>\n",
              "      <td>-0.8554</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>-2.3520</td>\n",
              "      <td>2.1200</td>\n",
              "      <td>-1.1580</td>\n",
              "      <td>-0.7191</td>\n",
              "      <td>-0.8004</td>\n",
              "      <td>-1.4670</td>\n",
              "      <td>-0.0107</td>\n",
              "      <td>-0.8995</td>\n",
              "      <td>0.2406</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-1.0890</td>\n",
              "      <td>-0.7575</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>-2.7370</td>\n",
              "      <td>0.8745</td>\n",
              "      <td>0.5787</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.3820</td>\n",
              "      <td>-3.7350</td>\n",
              "      <td>-2.9740</td>\n",
              "      <td>-1.4930</td>\n",
              "      <td>-1.6600</td>\n",
              "      <td>-3.1660</td>\n",
              "      <td>0.2816</td>\n",
              "      <td>-0.2990</td>\n",
              "      <td>-1.1870</td>\n",
              "      <td>-0.5044</td>\n",
              "      <td>-1.7750</td>\n",
              "      <td>-1.6120</td>\n",
              "      <td>-0.9215</td>\n",
              "      <td>-1.0810</td>\n",
              "      <td>-3.0520</td>\n",
              "      <td>-3.4470</td>\n",
              "      <td>-2.7740</td>\n",
              "      <td>-1.8460</td>\n",
              "      <td>-0.5568</td>\n",
              "      <td>-3.3960</td>\n",
              "      <td>-2.9510</td>\n",
              "      <td>-1.1550</td>\n",
              "      <td>-3.2620</td>\n",
              "      <td>-1.5390</td>\n",
              "      <td>-2.4600</td>\n",
              "      <td>-0.9417</td>\n",
              "      <td>-1.5550</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>-2.0990</td>\n",
              "      <td>-0.6441</td>\n",
              "      <td>-5.6300</td>\n",
              "      <td>-1.3780</td>\n",
              "      <td>-0.8632</td>\n",
              "      <td>-1.2880</td>\n",
              "      <td>-1.6210</td>\n",
              "      <td>-0.8784</td>\n",
              "      <td>-0.3876</td>\n",
              "      <td>-0.8154</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D2</td>\n",
              "      <td>7cbed3131</td>\n",
              "      <td>-0.3254</td>\n",
              "      <td>-0.4009</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>1.4180</td>\n",
              "      <td>-0.8244</td>\n",
              "      <td>-0.2800</td>\n",
              "      <td>-0.1498</td>\n",
              "      <td>-0.8789</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>-0.5121</td>\n",
              "      <td>-0.9577</td>\n",
              "      <td>1.1750</td>\n",
              "      <td>0.2042</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1244</td>\n",
              "      <td>-1.7090</td>\n",
              "      <td>-0.3543</td>\n",
              "      <td>-0.5160</td>\n",
              "      <td>-0.3330</td>\n",
              "      <td>-0.2685</td>\n",
              "      <td>0.7649</td>\n",
              "      <td>0.2057</td>\n",
              "      <td>1.3720</td>\n",
              "      <td>0.6835</td>\n",
              "      <td>0.8056</td>\n",
              "      <td>-0.3754</td>\n",
              "      <td>-1.2090</td>\n",
              "      <td>0.2965</td>\n",
              "      <td>-0.0712</td>\n",
              "      <td>0.6389</td>\n",
              "      <td>0.6674</td>\n",
              "      <td>-0.0783</td>\n",
              "      <td>1.1740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1535</td>\n",
              "      <td>-0.4640</td>\n",
              "      <td>-0.5943</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>0.5159</td>\n",
              "      <td>0.6091</td>\n",
              "      <td>0.1813</td>\n",
              "      <td>-0.4249</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>0.5648</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.0587</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.6376</td>\n",
              "      <td>-0.3966</td>\n",
              "      <td>-1.4950</td>\n",
              "      <td>-0.9625</td>\n",
              "      <td>-0.0541</td>\n",
              "      <td>0.6273</td>\n",
              "      <td>0.4563</td>\n",
              "      <td>0.0698</td>\n",
              "      <td>0.8134</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.6054</td>\n",
              "      <td>-0.1824</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.6670</td>\n",
              "      <td>1.0690</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.3031</td>\n",
              "      <td>0.1094</td>\n",
              "      <td>0.2885</td>\n",
              "      <td>-0.3786</td>\n",
              "      <td>0.7125</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 879 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id tratamento  tempo dose  ...     c98     c99  n_moa  ativo_moa\n",
              "0  id_000644bb2  com_droga     24   D1  ...  0.3801  0.4176      1          1\n",
              "1  id_000779bfc  com_droga     72   D1  ...  0.6077  0.7371      0          0\n",
              "2  id_000a6266a  com_droga     48   D1  ... -1.4080  0.6931      3          1\n",
              "3  id_0015fd391  com_droga     48   D1  ... -0.3876 -0.8154      0          0\n",
              "4  id_001626bd3  com_droga     72   D2  ... -0.3786  0.7125      1          1\n",
              "\n",
              "[5 rows x 879 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lToXro6chTl5"
      },
      "source": [
        "df_total['Eh controle'] = (df_total['tratamento'] == 'com_controle')*1\n",
        "df_total['Tempo eh 24'] = (df_total['tempo'] == 24)*1\n",
        "df_total['Tempo eh 48'] = (df_total['tempo'] == 48)*1\n",
        "df_total['Tempo eh 72'] = (df_total['tempo'] == 72)*1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVt09sZTr07z"
      },
      "source": [
        "# Máquinas preditivas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oLuLFXor5Bn"
      },
      "source": [
        "## Conceitos importantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xujwv4CjEBUj"
      },
      "source": [
        "Antes iniciarmos a construção dos modelos, é necessário explicar alguns conceitos que surgirão em nossa análise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMUFjGR7EKPs"
      },
      "source": [
        "A acurácia ('score', definida como total de acertos / total de amostras) não será a única métrica que utilizaremos para analisar a performace dos nossos modelos. Dependendo dos aspectos do problema de negócio, podemos estar interessandos em outras métricas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH2ljE_NEv3H"
      },
      "source": [
        "Uma boa maneira de começar a melhorar a análise da performace do modelo é verificar sua matriz de confusão ('confusion matrix'). Nas linhas dessa matriz temos os resultados reais e nas colunas temos os resultados previstos pelo modelo, de acordo com cada classe. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJk8vE0fFNYw"
      },
      "source": [
        "Em problemas de classificação binária, será uma matrix 2x2. \n",
        "\n",
        "Nas células dessa matriz, temos 4 informações importantes:\n",
        "- VP = número de verdadeiros positivos (modelo previu que era positivo e de fato era positivo)\n",
        "- VN = número de verdadeiros negativos (modelo previu que era negativo e de fato era negativo)\n",
        "- FP = número de falsos positivos (modelo previu que era positivo, mas na verdade era negativo)\n",
        "- FN = número de falsos negativos (modelo previu que era negativo, mas na verdade era positivo)\n",
        "\n",
        "Dependendo do nosso problema, talvez queiramos um modelo com baixa proporção de falsos negativos, ou talvez uma baixa proporção de falsos positivos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11MPjv8xGH2l"
      },
      "source": [
        "Temos métricas que medem isso:\n",
        "- precisão de positos = VP/(VP+FP)\n",
        "- precisão de negativos = VN/(VN+FN)\n",
        "- recall (ou revocação) de positivos = VP/(VP+FN)\n",
        "- recall (ou revocação) de negativos = VN/(VN+FP)\n",
        "- F1 = média harmônica entre presicão e revocação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvaOobbw5Ti_"
      },
      "source": [
        "## Problema 1: Prevendo se o composto ativa algum MOA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0F-07k4JMNC"
      },
      "source": [
        "Como primeiro exemplo, vamos constuir máquinas que prevem se um composto ativa pelo menos um MOA (sem especificar qual é o MOA). Compostos que não ativam nenhum MOA provavelmente não são interessantes. \n",
        "Nesse caso, não queremos correr o risco de prever que um composto ativa, porém na verdade não ativa. Ou seja, falsos positivos não são bem-vindos nesse problema. Logo estamos interessando em modelos com alta precisão para positivos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiGQoodL4_uI"
      },
      "source": [
        "Para começar, devemos separar, dentre as colunas do nosso data frame, aquelas que servirão para alimentar as máquinas preditivas e aquela que será a informação a ser prevista. \n",
        "Nesse primeiro momento, como variável a ser prevista, utilizaremos y = ativo_moa, isto é, vamos prever se o composto irá ou não ativar algum moa. \n",
        "Como parâmetros na variável x, iremos passar dados de dose, tempo, as expressões gênicas e as viabilidades celuares. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvFlCa8v71am"
      },
      "source": [
        "Importante lembrar que já observamos que as viabilidades celuares são variáveis com alta correção entre si. Talvez seja então interessante não considerar todas elas no modelo preditivo. Como já vimos na Aula 5 que as máquinas construídas lá não obtivaram um score muito bom e foram utilizadas todas as viabilidades celuares, nos meus modelos decidi utilizar apenas c0 e ver se os resultados são melhores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBovQfHi7yE0"
      },
      "source": [
        "y = df_total['ativo_moa']\n",
        "x_aux = df_total.drop(['id', 'tratamento', 'tempo','dose', 'composto', 'ativo_moa'], axis = 1)\n",
        "x = x_aux.drop(x_aux.columns[773:873], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jQgJj-ZAP2P"
      },
      "source": [
        "Agora iremos separar nossos conjuntos de treino e conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9rA5Oy5Ar6b"
      },
      "source": [
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x,y, test_size = 0.3, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFXlstGhA5x-"
      },
      "source": [
        "Estamos prontos para começar a testar os modelos preditivos.\n",
        "Vamos criar também um dataframe com informações sumarizadas das performaces de cada modelo, para que possamos compará-los no final. Criaremos listas que coletarão os resultados das métricas de análise e no fim do processo utilizaremos essas listas como colunas do nosso dataframe. Assim:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss-LzCQwBMsf"
      },
      "source": [
        "lista_modelo = []\n",
        "lista_score = []\n",
        "lista_precision0 = [] \n",
        "lista_precision1 = []\n",
        "lista_recall0 = []\n",
        "lista_recall1 = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqrF52gCBU_Z"
      },
      "source": [
        "### Regressão Logistica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqIPwGRPBY9F",
        "outputId": "97771154-7ae3-4c87-b59b-d81177289ca8"
      },
      "source": [
        "modelo = LogisticRegression()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  66.01819454163751 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E0X_LgUC7EZ",
        "outputId": "2be8f364-4341-4da6-af39-4f4a41c6dcf3"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1043 1767]\n",
            " [ 661 3674]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfhAOfjpDBZS",
        "outputId": "482218df-f02d-4f09-f890-9da994e015ee"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.37      0.46      2810\n",
            "           1       0.68      0.85      0.75      4335\n",
            "\n",
            "    accuracy                           0.66      7145\n",
            "   macro avg       0.64      0.61      0.61      7145\n",
            "weighted avg       0.65      0.66      0.64      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3cNQjjnDrfM"
      },
      "source": [
        "### DecisionTreeClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdoOXNN_Dzc3",
        "outputId": "05e21d44-fbbc-4154-b817-7b1af238fd62"
      },
      "source": [
        "modelo = DecisionTreeClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  62.02939118264521 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv-wbN70DkML",
        "outputId": "0b033199-8157-44f8-e185-43ab6030aa77"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1441 1369]\n",
            " [1344 2991]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFu7QY6jDmSM",
        "outputId": "ffa74572-ac43-4c88-f3bd-697c8bc4cb8e"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.51      0.52      2810\n",
            "           1       0.69      0.69      0.69      4335\n",
            "\n",
            "    accuracy                           0.62      7145\n",
            "   macro avg       0.60      0.60      0.60      7145\n",
            "weighted avg       0.62      0.62      0.62      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9orZESuEB8o"
      },
      "source": [
        "### RandomFlorestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZbsILWnEIp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82b2da0-6adb-4ec1-af5e-08692a20d599"
      },
      "source": [
        "modelo = RandomForestClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  67.30580825752274 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImfPh_3HD3sR",
        "outputId": "d8c87a05-bdee-4ff4-fd4a-5674ede56de4"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 783 2027]\n",
            " [ 309 4026]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oltkDwvD5Yx",
        "outputId": "96673b1e-027c-436d-8c6f-b7ce5f7a3574"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.28      0.40      2810\n",
            "           1       0.67      0.93      0.78      4335\n",
            "\n",
            "    accuracy                           0.67      7145\n",
            "   macro avg       0.69      0.60      0.59      7145\n",
            "weighted avg       0.69      0.67      0.63      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0w6drIlEhWp"
      },
      "source": [
        "### LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNfVmGOPErTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638c30b4-c2eb-42a8-ae2d-1daac146e055"
      },
      "source": [
        "modelo = LGBMClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  68.24352694191742 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QUuaTJtER8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997bb943-0daf-407d-d219-6de75d4a6b16"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 808 2002]\n",
            " [ 267 4068]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY3SXSxbET9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59183cd1-0a3f-4f4f-ae45-4046adb0db1a"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.29      0.42      2810\n",
            "           1       0.67      0.94      0.78      4335\n",
            "\n",
            "    accuracy                           0.68      7145\n",
            "   macro avg       0.71      0.61      0.60      7145\n",
            "weighted avg       0.70      0.68      0.64      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCVo8JpOT3N"
      },
      "source": [
        "### XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-wLA-C3OMlx",
        "outputId": "ff3b269d-4004-4736-ffae-be34ef9a92d1"
      },
      "source": [
        "modelo = XGBClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  68.99930020993702 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ba0aYiOarq",
        "outputId": "03d9e55d-dc31-48ff-92fd-23469a2cb64b"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 630 2180]\n",
            " [  35 4300]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh81BxZGOctr",
        "outputId": "155fe650-837b-41f7-9922-78963a56efe4"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.22      0.36      2810\n",
            "           1       0.66      0.99      0.80      4335\n",
            "\n",
            "    accuracy                           0.69      7145\n",
            "   macro avg       0.81      0.61      0.58      7145\n",
            "weighted avg       0.78      0.69      0.63      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1G38Y-qE6Zk"
      },
      "source": [
        "### GradientBoostingClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2yQhhwkFA8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae98873-8e33-43cc-ef0a-d4841cf99273"
      },
      "source": [
        "modelo = GradientBoostingClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  69.06927921623513 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xo1Jns3FSyF",
        "outputId": "0f324b26-a713-4eab-8bda-8373a10e4e04"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 642 2168]\n",
            " [  42 4293]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UWVeEQiFUbi",
        "outputId": "cf2d3b12-1303-4ce8-b653-e15ce4205145"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.23      0.37      2810\n",
            "           1       0.66      0.99      0.80      4335\n",
            "\n",
            "    accuracy                           0.69      7145\n",
            "   macro avg       0.80      0.61      0.58      7145\n",
            "weighted avg       0.77      0.69      0.63      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH0D1RycG7bQ"
      },
      "source": [
        "### KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNpnxVuRG9Nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c7f55b-2c05-4881-e5fc-045118663eaf"
      },
      "source": [
        "modelo = KNeighborsClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  61.371588523442966 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izTTxUfoJZYG",
        "outputId": "60cd4f8f-bc45-4ee3-816d-ab8382512ebd"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1020 1790]\n",
            " [ 970 3365]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgdCu0P0Jbsy",
        "outputId": "4a26005e-0a24-489d-b696-eaea04c0821a"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.36      0.42      2810\n",
            "           1       0.65      0.78      0.71      4335\n",
            "\n",
            "    accuracy                           0.61      7145\n",
            "   macro avg       0.58      0.57      0.57      7145\n",
            "weighted avg       0.60      0.61      0.60      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCTODSJqIIm-"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP3oNBLqIiqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92280d01-1948-400a-95d7-ae9d859fbc26"
      },
      "source": [
        "modelo = SVC()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  68.45346396081176 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOoe-IVkKr2z",
        "outputId": "46f60c24-d6b9-4572-cc50-4eadd8eb6227"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 702 2108]\n",
            " [ 146 4189]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYKPYOH1KuSp",
        "outputId": "ffa16846-4bdd-4ba9-8225-c27eaeff2b75"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.25      0.38      2810\n",
            "           1       0.67      0.97      0.79      4335\n",
            "\n",
            "    accuracy                           0.68      7145\n",
            "   macro avg       0.75      0.61      0.59      7145\n",
            "weighted avg       0.73      0.68      0.63      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idbuvw7DYQ_-"
      },
      "source": [
        "### Resumo "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul6ukhaLsbN8"
      },
      "source": [
        "Vamos sumarizar essas informações sobre a performace das máquinas preditivas em uma tabela. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcggtNg6SAPR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "3fcea4a2-c3fb-43e8-e3a8-b702109fe387"
      },
      "source": [
        "Tabela_Performace_Modelos = pd.DataFrame()\n",
        "Tabela_Performace_Modelos['Modelo'] = lista_modelo\n",
        "Tabela_Performace_Modelos['Score'] = lista_score\n",
        "Tabela_Performace_Modelos['precision-0'] = lista_precision0\n",
        "Tabela_Performace_Modelos['precision-1'] = lista_precision1\n",
        "Tabela_Performace_Modelos['recall-0'] = lista_recall0\n",
        "Tabela_Performace_Modelos['recall-1'] = lista_recall1\n",
        "\n",
        "Tabela_Comparação_Modelos_Problema1 = Tabela_Performace_Modelos\n",
        "Tabela_Comparação_Modelos_Problema1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Score</th>\n",
              "      <th>precision-0</th>\n",
              "      <th>precision-1</th>\n",
              "      <th>recall-0</th>\n",
              "      <th>recall-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.660182</td>\n",
              "      <td>0.612089</td>\n",
              "      <td>0.675244</td>\n",
              "      <td>0.371174</td>\n",
              "      <td>0.847520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.620294</td>\n",
              "      <td>0.517415</td>\n",
              "      <td>0.686009</td>\n",
              "      <td>0.512811</td>\n",
              "      <td>0.689965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.673058</td>\n",
              "      <td>0.717033</td>\n",
              "      <td>0.665125</td>\n",
              "      <td>0.278648</td>\n",
              "      <td>0.928720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBMClassifier</td>\n",
              "      <td>0.682435</td>\n",
              "      <td>0.751628</td>\n",
              "      <td>0.670181</td>\n",
              "      <td>0.287544</td>\n",
              "      <td>0.938408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.689993</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.663580</td>\n",
              "      <td>0.224199</td>\n",
              "      <td>0.991926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.690693</td>\n",
              "      <td>0.938596</td>\n",
              "      <td>0.664448</td>\n",
              "      <td>0.228470</td>\n",
              "      <td>0.990311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.613716</td>\n",
              "      <td>0.512563</td>\n",
              "      <td>0.652764</td>\n",
              "      <td>0.362989</td>\n",
              "      <td>0.776240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.684535</td>\n",
              "      <td>0.827830</td>\n",
              "      <td>0.665237</td>\n",
              "      <td>0.249822</td>\n",
              "      <td>0.966321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Modelo     Score  ...  recall-0  recall-1\n",
              "0          LogisticRegression  0.660182  ...  0.371174  0.847520\n",
              "1      DecisionTreeClassifier  0.620294  ...  0.512811  0.689965\n",
              "2      RandomForestClassifier  0.673058  ...  0.278648  0.928720\n",
              "3              LGBMClassifier  0.682435  ...  0.287544  0.938408\n",
              "4               XGBClassifier  0.689993  ...  0.224199  0.991926\n",
              "5  GradientBoostingClassifier  0.690693  ...  0.228470  0.990311\n",
              "6        KNeighborsClassifier  0.613716  ...  0.362989  0.776240\n",
              "7                         SVC  0.684535  ...  0.249822  0.966321\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSwobzs7Yi5_"
      },
      "source": [
        "Percebemos então que a acurácia dos modelos não é boa. Mas como já explicado, estamos também muito interessados na precisão dos resultados positivos, o que também não são bons, nunca chegando a 70%. \n",
        "Levando em conta a acurácia e a precisão, concluímos que nenhum dos modelos é satisfatório para resolver o Problema 1. O que faz sentindo, pois perguntar se ativa algum moa parece algo bastante vago. \n",
        "Está claro então que precisamos melhorar a pergunta que queremos responder utilizando a máquina preditiva. Vamos mudar a abordagem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyhyjflEYxud"
      },
      "source": [
        "## Problema 2: Prevendo se o composto ativa 2 ou mais MOAs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRsW76cGZmu5"
      },
      "source": [
        "No Problema 1 estávamos interessando em saber se um composto ativa pelo menos 1 MOA. O Problema 2 é similar: queremos saber se um composto, com base em suas expressões gênicas, ativa 2 ou mais MOA. Ainda é uma pergunta vaga, mas veremos que os resultados são mais animadores. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVAcmXiotjPd"
      },
      "source": [
        "Vamos começar definindo a nossa variável alvo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHHxP47oZn9O"
      },
      "source": [
        "df_total['ativa_2moa'] = (df_total['n_moa'] > 1)*1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RroE23Z-toYm"
      },
      "source": [
        "Vejamos como é a distrubuição de valores dessa variável:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhblrreFZ96-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611e8c54-73a4-4c7f-ff1c-f542b8b3e979"
      },
      "source": [
        "df_total['ativa_2moa'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    21899\n",
              "1     1915\n",
              "Name: ativa_2moa, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xm1qirOttPC"
      },
      "source": [
        "Observamos então que os dados estão bem desbalanceados. Isso pode afetar o desepenho dos modelos preditivos. Nesse tipo de cenário, é razoável esperar uma acurácia muito alta. Por esse motivo, mais do que nunca, é crucial considerar também a precisão de positivos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqPlkWDFcdid"
      },
      "source": [
        "y = df_total['ativa_2moa']\n",
        "x_aux = df_total.drop(['id', 'tratamento', 'tempo','dose', 'composto', 'ativo_moa', 'ativa_2moa'], axis = 1)\n",
        "x = x_aux.drop(x_aux.columns[773:873], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-oxNMx_bcfQ"
      },
      "source": [
        "Agora iremos separar nossos conjuntos de treino e conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx0shdnQbcfQ"
      },
      "source": [
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x,y, test_size = 0.3, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG1IAH1ubcfR"
      },
      "source": [
        "Como antes, vamos criar também um dataframe com informações sumarizadas das performaces de cada modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRX-I9IcbcfR"
      },
      "source": [
        "lista_modelo = []\n",
        "lista_score = []\n",
        "lista_precision0 = [] \n",
        "lista_precision1 = []\n",
        "lista_recall0 = []\n",
        "lista_recall1 = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NTC4wRRbcfS"
      },
      "source": [
        "### Regressão Logistica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmABPkPfbcfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7cc48b-9c8d-4113-ce78-be090d30cbd5"
      },
      "source": [
        "modelo = LogisticRegression()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  94.61161651504548 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifFgI6bVra20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ad54f4-cb73-47f8-9f63-f547eafa1f4e"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6527   43]\n",
            " [ 342  233]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_L2NW0Uq63h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb057e84-c604-4934-accd-d556d47fc6cb"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      6570\n",
            "           1       0.84      0.41      0.55       575\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.90      0.70      0.76      7145\n",
            "weighted avg       0.94      0.95      0.94      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSuCAhvQbcfT"
      },
      "source": [
        "### DecisionTreeClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOQAJcC3bcfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c423c9-2b3e-44bb-e6b9-747e55df5290"
      },
      "source": [
        "modelo = DecisionTreeClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  89.58712386284114 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7ldQAvhrY_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6681f0-fcbe-4877-c366-c2bd974f4ae8"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6158  412]\n",
            " [ 332  243]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYlmDjlxq5-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3e9098-1957-478f-d1c1-0437d9f5f54c"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94      6570\n",
            "           1       0.37      0.42      0.40       575\n",
            "\n",
            "    accuracy                           0.90      7145\n",
            "   macro avg       0.66      0.68      0.67      7145\n",
            "weighted avg       0.90      0.90      0.90      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9mX1MA6bcfT"
      },
      "source": [
        "### RandomFlorestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azlFQ0cIbcfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7934e0a5-0377-45fa-fcf1-9bc0e166bbc4"
      },
      "source": [
        "modelo = RandomForestClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  94.9335199440168 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0MVQgjlrX5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "596231c4-7825-4d68-e02a-0e606cc77c32"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6562    8]\n",
            " [ 354  221]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0FAFk1rq5Ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5651ee02-9368-401e-c2d8-5974da2bf096"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      6570\n",
            "           1       0.97      0.38      0.55       575\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.96      0.69      0.76      7145\n",
            "weighted avg       0.95      0.95      0.94      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACplOVe2bcfW"
      },
      "source": [
        "### LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WkydbLsbcfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a454610c-ecaf-4487-dc42-ec26e7e1b080"
      },
      "source": [
        "modelo = LGBMClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  95.01749475157453 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebRDyv09rWmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe32c839-bdfa-41c9-f024-bd38b06b9cff"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6563    7]\n",
            " [ 349  226]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGJbaE26q4F-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a329d1fc-ea34-484a-f356-dc26b9cd0eca"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      6570\n",
            "           1       0.97      0.39      0.56       575\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.96      0.70      0.77      7145\n",
            "weighted avg       0.95      0.95      0.94      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGLu1fuiPap9"
      },
      "source": [
        "### XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXTNzLuvPaqC",
        "outputId": "66860b1d-eae0-4cb5-a26d-83a588ce6a52"
      },
      "source": [
        "modelo = XGBClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  94.96151154653603 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6t2RCcPPaqD",
        "outputId": "d7dda5c2-7d46-4482-f285-6bcdc68fec90"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6563    7]\n",
            " [ 353  222]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io7sTjGGPaqE",
        "outputId": "94ec5eb0-a1a8-49dc-afdc-795abf2adf53"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      6570\n",
            "           1       0.97      0.39      0.55       575\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.96      0.69      0.76      7145\n",
            "weighted avg       0.95      0.95      0.94      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOG1xhgbcfX"
      },
      "source": [
        "### GradientBoostingClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPPFh33TbcfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c387de28-b48b-4f6b-e366-ca59f2ecee25"
      },
      "source": [
        "modelo = GradientBoostingClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  94.77956613016096 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDJ899TirVnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1e90e8-db74-406b-e941-240ee82ed954"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6551   19]\n",
            " [ 354  221]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv2SqvBpq27y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea346bc0-a4b9-47c9-b820-d40f90c5f114"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      6570\n",
            "           1       0.92      0.38      0.54       575\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.93      0.69      0.76      7145\n",
            "weighted avg       0.95      0.95      0.94      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRkkzrD-bcfX"
      },
      "source": [
        "### KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErIoCX_5bcfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8814921-fd07-44fc-ce0d-b08b39be6873"
      },
      "source": [
        "modelo = KNeighborsClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  94.6815955213436 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGmmhUcbrUrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483e21a5-e492-4ebe-f188-4594c261281b"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6542   28]\n",
            " [ 352  223]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiiNSDcvq1ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cd04c3-232c-4306-e144-5b576aa8ce43"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      6570\n",
            "           1       0.89      0.39      0.54       575\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.92      0.69      0.76      7145\n",
            "weighted avg       0.94      0.95      0.94      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZL0kY7bcfX"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v8hAfgkbcfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1188f4-1119-452b-d408-7087bc3af770"
      },
      "source": [
        "modelo = SVC()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  94.63960811756473 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfglqRTqrTvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbc1db7-c673-4b39-de42-2058f838a1bc"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6563    7]\n",
            " [ 376  199]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0vErQCvq0Y8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cca09c2-11fb-481b-cb16-64abfa97f6b1"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      6570\n",
            "           1       0.97      0.35      0.51       575\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.96      0.67      0.74      7145\n",
            "weighted avg       0.95      0.95      0.93      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbNO29UGYJHT"
      },
      "source": [
        "### Resumo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fVOMuq4bcfY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d453e3ba-f0b3-42f2-d3f8-8ffdab8b80b2"
      },
      "source": [
        "Tabela_Performace_Modelos = pd.DataFrame()\n",
        "Tabela_Performace_Modelos['Modelo'] = lista_modelo\n",
        "Tabela_Performace_Modelos['Score'] = lista_score\n",
        "Tabela_Performace_Modelos['precision-0'] = lista_precision0\n",
        "Tabela_Performace_Modelos['precision-1'] = lista_precision1\n",
        "Tabela_Performace_Modelos['recall-0'] = lista_recall0\n",
        "Tabela_Performace_Modelos['recall-1'] = lista_recall1\n",
        "\n",
        "Tabela_Comparação_Modelos_Problema2 = Tabela_Performace_Modelos\n",
        "Tabela_Comparação_Modelos_Problema2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Score</th>\n",
              "      <th>precision-0</th>\n",
              "      <th>precision-1</th>\n",
              "      <th>recall-0</th>\n",
              "      <th>recall-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.946116</td>\n",
              "      <td>0.950211</td>\n",
              "      <td>0.844203</td>\n",
              "      <td>0.993455</td>\n",
              "      <td>0.405217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.895871</td>\n",
              "      <td>0.948844</td>\n",
              "      <td>0.370992</td>\n",
              "      <td>0.937291</td>\n",
              "      <td>0.422609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.949335</td>\n",
              "      <td>0.948814</td>\n",
              "      <td>0.965066</td>\n",
              "      <td>0.998782</td>\n",
              "      <td>0.384348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBMClassifier</td>\n",
              "      <td>0.950175</td>\n",
              "      <td>0.949508</td>\n",
              "      <td>0.969957</td>\n",
              "      <td>0.998935</td>\n",
              "      <td>0.393043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.949615</td>\n",
              "      <td>0.948959</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.998935</td>\n",
              "      <td>0.386087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.947796</td>\n",
              "      <td>0.948733</td>\n",
              "      <td>0.920833</td>\n",
              "      <td>0.997108</td>\n",
              "      <td>0.384348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.946816</td>\n",
              "      <td>0.948941</td>\n",
              "      <td>0.888446</td>\n",
              "      <td>0.995738</td>\n",
              "      <td>0.387826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.946396</td>\n",
              "      <td>0.945814</td>\n",
              "      <td>0.966019</td>\n",
              "      <td>0.998935</td>\n",
              "      <td>0.346087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Modelo     Score  ...  recall-0  recall-1\n",
              "0          LogisticRegression  0.946116  ...  0.993455  0.405217\n",
              "1      DecisionTreeClassifier  0.895871  ...  0.937291  0.422609\n",
              "2      RandomForestClassifier  0.949335  ...  0.998782  0.384348\n",
              "3              LGBMClassifier  0.950175  ...  0.998935  0.393043\n",
              "4               XGBClassifier  0.949615  ...  0.998935  0.386087\n",
              "5  GradientBoostingClassifier  0.947796  ...  0.997108  0.384348\n",
              "6        KNeighborsClassifier  0.946816  ...  0.995738  0.387826\n",
              "7                         SVC  0.946396  ...  0.998935  0.346087\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzgXy4zU6OAA"
      },
      "source": [
        "Vemos que para o Problema 2, a acurácia de todos os modelos foi bastante alta, acima de 94%, como era de se esperar. Por isso, damos atenção à métrica precisão e notamos que também estão razoáveis. \n",
        "Com excessão do modelo de árvore de decisão, todos os outros modelos tiveram uma precisão acima de 84%. Alguns obtiveram precisão acima de 96%, o que é impressionante. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzNtuBMp68NY"
      },
      "source": [
        "Porém, uma métrica tão boa assim não vem de graça. É razoável esperar que outra métricas sejam afetadas negativamente. Vemos que em todos os modelos, o recall de positivos é baixo, sempre menor que 45%. \n",
        "Ou seja, existe um número proporcionalmente grande de falsos negativos. No nosso problema de negócios, isso significa que haverá um número grande de compostos cujo modelo prevê que não ativará os MOAs, mas na verdade ele ativará. Estamos perdendo oportunidades. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ6IaBSB8F83"
      },
      "source": [
        "Mas vale frisar novamente que uma alta precisão para positivos significa que temos uma proporção baixa de falsos positivos. Ou seja, estamos correndo um risco menor de aprovar um composto que não funcione (ou funcione de uma maneira que não é a desejada). \n",
        "Fica a cargo do tomador de decisão escolher qual cenário é preferível. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idtsE00I0EIT"
      },
      "source": [
        "## Problema 3: Prevendo se o composto ativa um MOA específico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfqtt1c10EIZ"
      },
      "source": [
        "No Problema 1 estávamos interessando em saber se um composto ativa pelo menos 1 MOA. No Problema 3 estamos interessados em saber se o composto ativa um MOA de nossa escolha. Biologicamente, esse problema faz bastante sentido e é parece ser mais relevante. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvxHYVfL9LT7"
      },
      "source": [
        "Podemos ver esse problema sob duas perspectivas:\n",
        " \n",
        "\n",
        "1.   queremos garantir que o composto ative o MOA, pois é benéfico para o paciente\n",
        "2.   queremos garantir que o composto não ative o MOA, pois seria maléfico para o paciente\n",
        "\n",
        "\n",
        "\n",
        "No primeiro cenário, queremos uma baixa proporção de falsos positivos, ou seja, uma precisão alta para positivos. No segundo cenário, queremos uma proporção baixa para falsos negativos, ou seja, uma precisão alta para negativos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8wjEpzj4Dx6"
      },
      "source": [
        "Para efeito de exemplificação, vamos escolher o MOA proteasome_inhibitor. Esse é o MOA que mais foi ativado, com 762 ativações. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_OQGBxc4nJj"
      },
      "source": [
        "Para realizarmos isso, vamos precisar criar um novo data frame, utilizando o merge. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2QBw7Vi-tWE"
      },
      "source": [
        "df_moa_ativado = pd.merge(df.iloc[:,0:778], df_resultados[['id','proteasome_inhibitor']], on='id')\n",
        "df_moa_ativado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBDdQxJx_SRh"
      },
      "source": [
        "df_moa_ativado['Eh controle'] = (df_moa_ativado['tratamento'] == 'com_controle')*1\n",
        "df_moa_ativado['Tempo eh 24'] = (df_moa_ativado['tempo'] == 24)*1\n",
        "df_moa_ativado['Tempo eh 48'] = (df_moa_ativado['tempo'] == 48)*1\n",
        "df_moa_ativado['Tempo eh 72'] = (df_moa_ativado['tempo'] == 72)*1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r48bdMkt-zxG"
      },
      "source": [
        "Criando as variáveis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbhcHP_p-2Q5"
      },
      "source": [
        "y = df_moa_ativado['proteasome_inhibitor']\n",
        "x = df_moa_ativado.drop(['id', 'tratamento','composto' ,'dose', 'tempo', 'proteasome_inhibitor'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o96mz0b3fel"
      },
      "source": [
        "Agora iremos separar nossos conjuntos de treino e conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EuWKeVp3fel"
      },
      "source": [
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x,y, test_size = 0.3, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHrngUBF3fel"
      },
      "source": [
        "Estamos prontos para começar a testar os modelos preditivos.\n",
        "Como antes, vamos criar também um dataframe com informações sumarizadas das performaces de cada modelo. Assim:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd8Y5fRz3fel"
      },
      "source": [
        "lista_modelo = []\n",
        "lista_score = []\n",
        "lista_precision0 = [] \n",
        "lista_precision1 = []\n",
        "lista_recall0 = []\n",
        "lista_recall1 = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElC4XwRh0EIe"
      },
      "source": [
        "### Regressão Logistica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFCPqx7Y0EIe",
        "outputId": "5df2fe54-2433-418a-e09d-1cc50a5662ad"
      },
      "source": [
        "modelo = LogisticRegression()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  99.95801259622114 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAPdYcBd0EIe",
        "outputId": "11bca82c-504a-4746-a237-12093470daf5"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6925    2]\n",
            " [   1  217]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5X5ObLi0EIf",
        "outputId": "cd03aaf3-b3b5-41c6-8af8-45fdc7035ee8"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6927\n",
            "           1       0.99      1.00      0.99       218\n",
            "\n",
            "    accuracy                           1.00      7145\n",
            "   macro avg       1.00      1.00      1.00      7145\n",
            "weighted avg       1.00      1.00      1.00      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpddCuag0EIf"
      },
      "source": [
        "### DecisionTreeClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhzFCVKU0EIf",
        "outputId": "6312c70c-5904-4d8f-aee0-eafe791aa4b8"
      },
      "source": [
        "modelo = DecisionTreeClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  99.72008397480757 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "085ej4Oi0EIf",
        "outputId": "c4502f63-ae85-45f0-f527-3375e61a28d7"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6918    9]\n",
            " [  11  207]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC0KsTWy0EIg",
        "outputId": "be4260f3-0383-402f-8922-83c5a00e535d"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6927\n",
            "           1       0.96      0.95      0.95       218\n",
            "\n",
            "    accuracy                           1.00      7145\n",
            "   macro avg       0.98      0.97      0.98      7145\n",
            "weighted avg       1.00      1.00      1.00      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR-j4-R30EIg"
      },
      "source": [
        "### RandomFlorestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRo00jKf0EIg",
        "outputId": "22ebdccf-9144-4b66-ac56-33081e92371a"
      },
      "source": [
        "modelo = RandomForestClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  99.94401679496151 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX4qTxSp0EIg",
        "outputId": "39a64c29-5fd3-4476-eeab-ed794836a9fd"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6924    3]\n",
            " [   1  217]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzIFdQGp0EIh",
        "outputId": "87a336c4-caf7-4005-e2e8-06d00eab7c45"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6927\n",
            "           1       0.99      1.00      0.99       218\n",
            "\n",
            "    accuracy                           1.00      7145\n",
            "   macro avg       0.99      1.00      1.00      7145\n",
            "weighted avg       1.00      1.00      1.00      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iPAF7n70EIh"
      },
      "source": [
        "### LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffX8mrz60EIh",
        "outputId": "648b532a-f0fd-42fa-a745-b53eba8b665e"
      },
      "source": [
        "modelo = LGBMClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  99.91602519244228 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7qA643t0EIh",
        "outputId": "ce2938f8-694e-44bb-f782-bb644c4b2d0a"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6924    3]\n",
            " [   3  215]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4rMfgHF0EIh",
        "outputId": "2dbe44c7-d87e-4040-a076-61de2a44e672"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6927\n",
            "           1       0.99      0.99      0.99       218\n",
            "\n",
            "    accuracy                           1.00      7145\n",
            "   macro avg       0.99      0.99      0.99      7145\n",
            "weighted avg       1.00      1.00      1.00      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaSt7SKP0EIi"
      },
      "source": [
        "### XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhPZ8Zao0EIi",
        "outputId": "ac646ca9-0a38-4e14-8a3e-414311eeb61d"
      },
      "source": [
        "modelo = XGBClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  99.91602519244228 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60A_Hhjm0EIi",
        "outputId": "17c5a060-1b33-4e53-a35f-249eb00a2581"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6924    3]\n",
            " [   3  215]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNfhy6PH0EIi",
        "outputId": "63bea6f3-007f-49ce-fe3b-ac56ec6342f8"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6927\n",
            "           1       0.99      0.99      0.99       218\n",
            "\n",
            "    accuracy                           1.00      7145\n",
            "   macro avg       0.99      0.99      0.99      7145\n",
            "weighted avg       1.00      1.00      1.00      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzEmZuUu0EIi"
      },
      "source": [
        "### GradientBoostingClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsa1PG2K0EIj",
        "outputId": "71b00148-116a-481e-efb1-ff59f50f0b44"
      },
      "source": [
        "modelo = GradientBoostingClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  99.88803358992303 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwmpYMNN0EIj",
        "outputId": "ba8de487-d01a-4da0-d597-937ae3eb494c"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6923    4]\n",
            " [   4  214]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rns4aHB70EIj",
        "outputId": "523d5527-59d9-4edd-d4a6-98cec49ef179"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6927\n",
            "           1       0.98      0.98      0.98       218\n",
            "\n",
            "    accuracy                           1.00      7145\n",
            "   macro avg       0.99      0.99      0.99      7145\n",
            "weighted avg       1.00      1.00      1.00      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qhr-oj_0EIl"
      },
      "source": [
        "### KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hZp1rbO0EIl",
        "outputId": "62c52172-e9f9-4a66-be14-a59a51c0cef3"
      },
      "source": [
        "modelo = KNeighborsClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  99.76207137858643 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXsnf8_k0EIl",
        "outputId": "cbbae76e-15a9-4c84-a7d0-3d4723d291a7"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6911   16]\n",
            " [   1  217]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCoy_4c30EIm",
        "outputId": "4f0f50de-bf37-4bfb-c8a8-b242374928ab"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6927\n",
            "           1       0.93      1.00      0.96       218\n",
            "\n",
            "    accuracy                           1.00      7145\n",
            "   macro avg       0.97      1.00      0.98      7145\n",
            "weighted avg       1.00      1.00      1.00      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZaJfkpj0EIm"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyY0j9cF0EIm",
        "outputId": "ba0fc4cf-fe35-4e63-c276-10701bd78246"
      },
      "source": [
        "modelo = SVC()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  99.65010496850944 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kos1iMvV0EIn",
        "outputId": "5950ee00-7bef-4839-d1f6-043a658c7799"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6922    5]\n",
            " [  20  198]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlDKU_gh0EIn",
        "outputId": "c9857500-1555-4fff-99c6-882ca4844a68"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6927\n",
            "           1       0.98      0.91      0.94       218\n",
            "\n",
            "    accuracy                           1.00      7145\n",
            "   macro avg       0.99      0.95      0.97      7145\n",
            "weighted avg       1.00      1.00      1.00      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CFiEHVY0EIn"
      },
      "source": [
        "### Resumo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "wvVxu95M0EIn",
        "outputId": "7944e6c4-cc93-4bb5-9e86-2caa01b5f572"
      },
      "source": [
        "Tabela_Performace_Modelos = pd.DataFrame()\n",
        "Tabela_Performace_Modelos['Modelo'] = lista_modelo\n",
        "Tabela_Performace_Modelos['Score'] = lista_score\n",
        "Tabela_Performace_Modelos['precision-0'] = lista_precision0\n",
        "Tabela_Performace_Modelos['precision-1'] = lista_precision1\n",
        "Tabela_Performace_Modelos['recall-0'] = lista_recall0\n",
        "Tabela_Performace_Modelos['recall-1'] = lista_recall1\n",
        "\n",
        "Tabela_Comparação_Modelos_Problema3 = Tabela_Performace_Modelos\n",
        "Tabela_Comparação_Modelos_Problema3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Score</th>\n",
              "      <th>precision-0</th>\n",
              "      <th>precision-1</th>\n",
              "      <th>recall-0</th>\n",
              "      <th>recall-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.999580</td>\n",
              "      <td>0.999856</td>\n",
              "      <td>0.990868</td>\n",
              "      <td>0.999711</td>\n",
              "      <td>0.995413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.997201</td>\n",
              "      <td>0.998412</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.998701</td>\n",
              "      <td>0.949541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.999440</td>\n",
              "      <td>0.999856</td>\n",
              "      <td>0.986364</td>\n",
              "      <td>0.999567</td>\n",
              "      <td>0.995413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBMClassifier</td>\n",
              "      <td>0.999160</td>\n",
              "      <td>0.999567</td>\n",
              "      <td>0.986239</td>\n",
              "      <td>0.999567</td>\n",
              "      <td>0.986239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.999160</td>\n",
              "      <td>0.999567</td>\n",
              "      <td>0.986239</td>\n",
              "      <td>0.999567</td>\n",
              "      <td>0.986239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.998880</td>\n",
              "      <td>0.999423</td>\n",
              "      <td>0.981651</td>\n",
              "      <td>0.999423</td>\n",
              "      <td>0.981651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.997621</td>\n",
              "      <td>0.999855</td>\n",
              "      <td>0.931330</td>\n",
              "      <td>0.997690</td>\n",
              "      <td>0.995413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.996501</td>\n",
              "      <td>0.997119</td>\n",
              "      <td>0.975369</td>\n",
              "      <td>0.999278</td>\n",
              "      <td>0.908257</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Modelo     Score  ...  recall-0  recall-1\n",
              "0          LogisticRegression  0.999580  ...  0.999711  0.995413\n",
              "1      DecisionTreeClassifier  0.997201  ...  0.998701  0.949541\n",
              "2      RandomForestClassifier  0.999440  ...  0.999567  0.995413\n",
              "3              LGBMClassifier  0.999160  ...  0.999567  0.986239\n",
              "4               XGBClassifier  0.999160  ...  0.999567  0.986239\n",
              "5  GradientBoostingClassifier  0.998880  ...  0.999423  0.981651\n",
              "6        KNeighborsClassifier  0.997621  ...  0.997690  0.995413\n",
              "7                         SVC  0.996501  ...  0.999278  0.908257\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB_tjFoELn1Z"
      },
      "source": [
        "Olhando os dados da tabela 3, concluímos que, para o Problema 3, todos os modelos tiveram excelente desemepenho, em todas as métricas. Não poderíamos pedir por algo melhor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmAfZwjHCsOJ"
      },
      "source": [
        "## Problema 4: Prevendo se o composto é do grupo de controle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xErN6rfeC1_q"
      },
      "source": [
        "Agora estamos interessado em outro tipo de situação. Imagine que por um erro alguns dos rótulos dos compostos foram perdidos. Agora não se sabe se o composto era do grupo de controle ou não. Gostaríamos de poder prever essa informação. \n",
        "Para esse problema, imagino que estamos interessados tanto em baixa proporção de falsos positivos quanto em baixa proporção de falsos negativos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nahSFPhhCsOP"
      },
      "source": [
        "Para realizarmos isso, vamos voltar ao nosso data frame df_total. Nossa variável alvo será 'Eh controle' e a máquina preditiva irá receber as expressões gênicas, a viabilidade celular, o tempo do experimento e as doses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "Ep06dHuuGX8z",
        "outputId": "6991095b-8262-4b7e-9159-a027c3964b5e"
      },
      "source": [
        "df_total"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tratamento</th>\n",
              "      <th>tempo</th>\n",
              "      <th>dose</th>\n",
              "      <th>composto</th>\n",
              "      <th>g0</th>\n",
              "      <th>g1</th>\n",
              "      <th>g2</th>\n",
              "      <th>g3</th>\n",
              "      <th>g4</th>\n",
              "      <th>g5</th>\n",
              "      <th>g6</th>\n",
              "      <th>g7</th>\n",
              "      <th>g8</th>\n",
              "      <th>g9</th>\n",
              "      <th>g10</th>\n",
              "      <th>g11</th>\n",
              "      <th>g12</th>\n",
              "      <th>g13</th>\n",
              "      <th>g14</th>\n",
              "      <th>g15</th>\n",
              "      <th>g16</th>\n",
              "      <th>g17</th>\n",
              "      <th>g18</th>\n",
              "      <th>g19</th>\n",
              "      <th>g20</th>\n",
              "      <th>g21</th>\n",
              "      <th>g22</th>\n",
              "      <th>g23</th>\n",
              "      <th>g24</th>\n",
              "      <th>g25</th>\n",
              "      <th>g26</th>\n",
              "      <th>g27</th>\n",
              "      <th>g28</th>\n",
              "      <th>g29</th>\n",
              "      <th>g30</th>\n",
              "      <th>g31</th>\n",
              "      <th>g32</th>\n",
              "      <th>g33</th>\n",
              "      <th>g34</th>\n",
              "      <th>...</th>\n",
              "      <th>c67</th>\n",
              "      <th>c68</th>\n",
              "      <th>c69</th>\n",
              "      <th>c70</th>\n",
              "      <th>c71</th>\n",
              "      <th>c72</th>\n",
              "      <th>c73</th>\n",
              "      <th>c74</th>\n",
              "      <th>c75</th>\n",
              "      <th>c76</th>\n",
              "      <th>c77</th>\n",
              "      <th>c78</th>\n",
              "      <th>c79</th>\n",
              "      <th>c80</th>\n",
              "      <th>c81</th>\n",
              "      <th>c82</th>\n",
              "      <th>c83</th>\n",
              "      <th>c84</th>\n",
              "      <th>c85</th>\n",
              "      <th>c86</th>\n",
              "      <th>c87</th>\n",
              "      <th>c88</th>\n",
              "      <th>c89</th>\n",
              "      <th>c90</th>\n",
              "      <th>c91</th>\n",
              "      <th>c92</th>\n",
              "      <th>c93</th>\n",
              "      <th>c94</th>\n",
              "      <th>c95</th>\n",
              "      <th>c96</th>\n",
              "      <th>c97</th>\n",
              "      <th>c98</th>\n",
              "      <th>c99</th>\n",
              "      <th>n_moa</th>\n",
              "      <th>ativo_moa</th>\n",
              "      <th>Eh controle</th>\n",
              "      <th>Tempo eh 24</th>\n",
              "      <th>Tempo eh 48</th>\n",
              "      <th>Tempo eh 72</th>\n",
              "      <th>ativa_2moa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D1</td>\n",
              "      <td>b68db1d53</td>\n",
              "      <td>1.0620</td>\n",
              "      <td>0.5577</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-0.6208</td>\n",
              "      <td>-0.1944</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>-1.0220</td>\n",
              "      <td>-0.0326</td>\n",
              "      <td>0.5548</td>\n",
              "      <td>-0.0921</td>\n",
              "      <td>1.1830</td>\n",
              "      <td>0.1530</td>\n",
              "      <td>0.5574</td>\n",
              "      <td>-0.4015</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>-0.6528</td>\n",
              "      <td>-0.7969</td>\n",
              "      <td>0.6342</td>\n",
              "      <td>0.1778</td>\n",
              "      <td>-0.3694</td>\n",
              "      <td>-0.5688</td>\n",
              "      <td>-1.1360</td>\n",
              "      <td>-1.1880</td>\n",
              "      <td>0.6940</td>\n",
              "      <td>0.4393</td>\n",
              "      <td>0.2664</td>\n",
              "      <td>0.1907</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>-0.2853</td>\n",
              "      <td>0.5819</td>\n",
              "      <td>0.2934</td>\n",
              "      <td>-0.5584</td>\n",
              "      <td>-0.0916</td>\n",
              "      <td>-0.3010</td>\n",
              "      <td>-0.1537</td>\n",
              "      <td>...</td>\n",
              "      <td>1.2570</td>\n",
              "      <td>-0.5979</td>\n",
              "      <td>1.2250</td>\n",
              "      <td>-0.0553</td>\n",
              "      <td>0.7351</td>\n",
              "      <td>0.5810</td>\n",
              "      <td>0.9590</td>\n",
              "      <td>0.2427</td>\n",
              "      <td>0.0495</td>\n",
              "      <td>0.4141</td>\n",
              "      <td>0.8432</td>\n",
              "      <td>0.6162</td>\n",
              "      <td>-0.7318</td>\n",
              "      <td>1.2120</td>\n",
              "      <td>0.6362</td>\n",
              "      <td>-0.4427</td>\n",
              "      <td>0.1288</td>\n",
              "      <td>1.4840</td>\n",
              "      <td>0.1799</td>\n",
              "      <td>0.5367</td>\n",
              "      <td>-0.1111</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>0.6685</td>\n",
              "      <td>0.2862</td>\n",
              "      <td>0.2584</td>\n",
              "      <td>0.8076</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.1912</td>\n",
              "      <td>0.6584</td>\n",
              "      <td>-0.3981</td>\n",
              "      <td>0.2139</td>\n",
              "      <td>0.3801</td>\n",
              "      <td>0.4176</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D1</td>\n",
              "      <td>df89a8e5a</td>\n",
              "      <td>0.0743</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.2991</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>1.0190</td>\n",
              "      <td>0.5207</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.3372</td>\n",
              "      <td>-0.4047</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>-1.1520</td>\n",
              "      <td>-0.4201</td>\n",
              "      <td>-0.0958</td>\n",
              "      <td>0.4590</td>\n",
              "      <td>0.0803</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>0.5293</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>-0.3494</td>\n",
              "      <td>0.2883</td>\n",
              "      <td>0.9449</td>\n",
              "      <td>-0.1646</td>\n",
              "      <td>-0.2657</td>\n",
              "      <td>-0.3372</td>\n",
              "      <td>0.3135</td>\n",
              "      <td>-0.4316</td>\n",
              "      <td>0.4773</td>\n",
              "      <td>0.2075</td>\n",
              "      <td>-0.4216</td>\n",
              "      <td>-0.1161</td>\n",
              "      <td>-0.0499</td>\n",
              "      <td>-0.2627</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>-0.2483</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.3104</td>\n",
              "      <td>-0.6373</td>\n",
              "      <td>0.2887</td>\n",
              "      <td>-0.0765</td>\n",
              "      <td>0.2539</td>\n",
              "      <td>0.4443</td>\n",
              "      <td>0.5932</td>\n",
              "      <td>0.2031</td>\n",
              "      <td>0.7639</td>\n",
              "      <td>0.5499</td>\n",
              "      <td>-0.3322</td>\n",
              "      <td>-0.0977</td>\n",
              "      <td>0.4329</td>\n",
              "      <td>-0.2782</td>\n",
              "      <td>0.7827</td>\n",
              "      <td>0.5934</td>\n",
              "      <td>0.3402</td>\n",
              "      <td>0.1499</td>\n",
              "      <td>0.4420</td>\n",
              "      <td>0.9366</td>\n",
              "      <td>0.8193</td>\n",
              "      <td>-0.4236</td>\n",
              "      <td>0.3192</td>\n",
              "      <td>-0.4265</td>\n",
              "      <td>0.7543</td>\n",
              "      <td>0.4708</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.2957</td>\n",
              "      <td>0.4899</td>\n",
              "      <td>0.1522</td>\n",
              "      <td>0.1241</td>\n",
              "      <td>0.6077</td>\n",
              "      <td>0.7371</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>18bb41b2c</td>\n",
              "      <td>0.6280</td>\n",
              "      <td>0.5817</td>\n",
              "      <td>1.5540</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.0323</td>\n",
              "      <td>1.2390</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>-0.4797</td>\n",
              "      <td>-0.5631</td>\n",
              "      <td>-0.0366</td>\n",
              "      <td>-1.8300</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>-0.3278</td>\n",
              "      <td>0.6042</td>\n",
              "      <td>-0.3075</td>\n",
              "      <td>-0.1147</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>-0.0799</td>\n",
              "      <td>-0.8181</td>\n",
              "      <td>-1.5320</td>\n",
              "      <td>0.2307</td>\n",
              "      <td>0.4901</td>\n",
              "      <td>0.4780</td>\n",
              "      <td>-1.3970</td>\n",
              "      <td>4.6240</td>\n",
              "      <td>-0.0437</td>\n",
              "      <td>1.2870</td>\n",
              "      <td>-1.8530</td>\n",
              "      <td>0.6069</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>0.1783</td>\n",
              "      <td>0.0018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>-0.5177</td>\n",
              "      <td>-0.0604</td>\n",
              "      <td>0.1682</td>\n",
              "      <td>-0.4436</td>\n",
              "      <td>0.4963</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.9760</td>\n",
              "      <td>-0.0427</td>\n",
              "      <td>-0.1235</td>\n",
              "      <td>0.0959</td>\n",
              "      <td>0.0690</td>\n",
              "      <td>-0.9416</td>\n",
              "      <td>-0.7548</td>\n",
              "      <td>-0.1109</td>\n",
              "      <td>-0.6272</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>0.1172</td>\n",
              "      <td>0.1093</td>\n",
              "      <td>-0.3113</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>-0.0873</td>\n",
              "      <td>-0.7250</td>\n",
              "      <td>-0.6297</td>\n",
              "      <td>0.6103</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>-1.3240</td>\n",
              "      <td>-0.3174</td>\n",
              "      <td>-0.6417</td>\n",
              "      <td>-0.2187</td>\n",
              "      <td>-1.4080</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>8c7f86626</td>\n",
              "      <td>-0.5138</td>\n",
              "      <td>-0.2491</td>\n",
              "      <td>-0.2656</td>\n",
              "      <td>0.5288</td>\n",
              "      <td>4.0620</td>\n",
              "      <td>-0.8095</td>\n",
              "      <td>-1.9590</td>\n",
              "      <td>0.1792</td>\n",
              "      <td>-0.1321</td>\n",
              "      <td>-1.0600</td>\n",
              "      <td>-0.8269</td>\n",
              "      <td>-0.3584</td>\n",
              "      <td>-0.8511</td>\n",
              "      <td>-0.5844</td>\n",
              "      <td>-2.5690</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>-0.0532</td>\n",
              "      <td>-0.8554</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>-2.3520</td>\n",
              "      <td>2.1200</td>\n",
              "      <td>-1.1580</td>\n",
              "      <td>-0.7191</td>\n",
              "      <td>-0.8004</td>\n",
              "      <td>-1.4670</td>\n",
              "      <td>-0.0107</td>\n",
              "      <td>-0.8995</td>\n",
              "      <td>0.2406</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-1.0890</td>\n",
              "      <td>-0.7575</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>-2.7370</td>\n",
              "      <td>0.8745</td>\n",
              "      <td>0.5787</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.1660</td>\n",
              "      <td>0.2816</td>\n",
              "      <td>-0.2990</td>\n",
              "      <td>-1.1870</td>\n",
              "      <td>-0.5044</td>\n",
              "      <td>-1.7750</td>\n",
              "      <td>-1.6120</td>\n",
              "      <td>-0.9215</td>\n",
              "      <td>-1.0810</td>\n",
              "      <td>-3.0520</td>\n",
              "      <td>-3.4470</td>\n",
              "      <td>-2.7740</td>\n",
              "      <td>-1.8460</td>\n",
              "      <td>-0.5568</td>\n",
              "      <td>-3.3960</td>\n",
              "      <td>-2.9510</td>\n",
              "      <td>-1.1550</td>\n",
              "      <td>-3.2620</td>\n",
              "      <td>-1.5390</td>\n",
              "      <td>-2.4600</td>\n",
              "      <td>-0.9417</td>\n",
              "      <td>-1.5550</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>-2.0990</td>\n",
              "      <td>-0.6441</td>\n",
              "      <td>-5.6300</td>\n",
              "      <td>-1.3780</td>\n",
              "      <td>-0.8632</td>\n",
              "      <td>-1.2880</td>\n",
              "      <td>-1.6210</td>\n",
              "      <td>-0.8784</td>\n",
              "      <td>-0.3876</td>\n",
              "      <td>-0.8154</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D2</td>\n",
              "      <td>7cbed3131</td>\n",
              "      <td>-0.3254</td>\n",
              "      <td>-0.4009</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>1.4180</td>\n",
              "      <td>-0.8244</td>\n",
              "      <td>-0.2800</td>\n",
              "      <td>-0.1498</td>\n",
              "      <td>-0.8789</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>-0.5121</td>\n",
              "      <td>-0.9577</td>\n",
              "      <td>1.1750</td>\n",
              "      <td>0.2042</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1244</td>\n",
              "      <td>-1.7090</td>\n",
              "      <td>-0.3543</td>\n",
              "      <td>-0.5160</td>\n",
              "      <td>-0.3330</td>\n",
              "      <td>-0.2685</td>\n",
              "      <td>0.7649</td>\n",
              "      <td>0.2057</td>\n",
              "      <td>1.3720</td>\n",
              "      <td>0.6835</td>\n",
              "      <td>0.8056</td>\n",
              "      <td>-0.3754</td>\n",
              "      <td>-1.2090</td>\n",
              "      <td>0.2965</td>\n",
              "      <td>-0.0712</td>\n",
              "      <td>0.6389</td>\n",
              "      <td>0.6674</td>\n",
              "      <td>-0.0783</td>\n",
              "      <td>1.1740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>0.5159</td>\n",
              "      <td>0.6091</td>\n",
              "      <td>0.1813</td>\n",
              "      <td>-0.4249</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>0.5648</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.0587</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.6376</td>\n",
              "      <td>-0.3966</td>\n",
              "      <td>-1.4950</td>\n",
              "      <td>-0.9625</td>\n",
              "      <td>-0.0541</td>\n",
              "      <td>0.6273</td>\n",
              "      <td>0.4563</td>\n",
              "      <td>0.0698</td>\n",
              "      <td>0.8134</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.6054</td>\n",
              "      <td>-0.1824</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.6670</td>\n",
              "      <td>1.0690</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.3031</td>\n",
              "      <td>0.1094</td>\n",
              "      <td>0.2885</td>\n",
              "      <td>-0.3786</td>\n",
              "      <td>0.7125</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23809</th>\n",
              "      <td>id_fffb1ceed</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D2</td>\n",
              "      <td>df1d0a5a1</td>\n",
              "      <td>0.1394</td>\n",
              "      <td>-0.0636</td>\n",
              "      <td>-0.1112</td>\n",
              "      <td>-0.5080</td>\n",
              "      <td>-0.4713</td>\n",
              "      <td>0.7201</td>\n",
              "      <td>0.5773</td>\n",
              "      <td>0.3055</td>\n",
              "      <td>-0.4726</td>\n",
              "      <td>0.1269</td>\n",
              "      <td>0.2531</td>\n",
              "      <td>0.1730</td>\n",
              "      <td>-0.4532</td>\n",
              "      <td>-1.0790</td>\n",
              "      <td>0.2474</td>\n",
              "      <td>-0.4550</td>\n",
              "      <td>0.3588</td>\n",
              "      <td>0.1600</td>\n",
              "      <td>-0.7362</td>\n",
              "      <td>-0.1103</td>\n",
              "      <td>0.8550</td>\n",
              "      <td>-0.4139</td>\n",
              "      <td>0.5541</td>\n",
              "      <td>0.2310</td>\n",
              "      <td>-0.5573</td>\n",
              "      <td>-0.4397</td>\n",
              "      <td>-0.9260</td>\n",
              "      <td>-0.2424</td>\n",
              "      <td>-0.6686</td>\n",
              "      <td>0.2326</td>\n",
              "      <td>0.6456</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>-0.5141</td>\n",
              "      <td>-0.6320</td>\n",
              "      <td>0.7166</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3154</td>\n",
              "      <td>-0.2071</td>\n",
              "      <td>-0.6158</td>\n",
              "      <td>-0.2977</td>\n",
              "      <td>0.0992</td>\n",
              "      <td>0.6838</td>\n",
              "      <td>0.5259</td>\n",
              "      <td>0.7882</td>\n",
              "      <td>0.3119</td>\n",
              "      <td>-0.7697</td>\n",
              "      <td>0.2203</td>\n",
              "      <td>-1.0710</td>\n",
              "      <td>0.5979</td>\n",
              "      <td>0.0848</td>\n",
              "      <td>-0.2555</td>\n",
              "      <td>0.6293</td>\n",
              "      <td>1.1660</td>\n",
              "      <td>0.3329</td>\n",
              "      <td>0.2754</td>\n",
              "      <td>0.4108</td>\n",
              "      <td>-0.1252</td>\n",
              "      <td>-0.2340</td>\n",
              "      <td>0.2267</td>\n",
              "      <td>0.1969</td>\n",
              "      <td>0.0262</td>\n",
              "      <td>-0.8121</td>\n",
              "      <td>0.3434</td>\n",
              "      <td>0.5372</td>\n",
              "      <td>-0.3246</td>\n",
              "      <td>0.0631</td>\n",
              "      <td>0.9171</td>\n",
              "      <td>0.5258</td>\n",
              "      <td>0.4680</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23810</th>\n",
              "      <td>id_fffb70c0c</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D2</td>\n",
              "      <td>ecf3b6b74</td>\n",
              "      <td>-1.3260</td>\n",
              "      <td>0.3478</td>\n",
              "      <td>-0.3743</td>\n",
              "      <td>0.9905</td>\n",
              "      <td>-0.7178</td>\n",
              "      <td>0.6621</td>\n",
              "      <td>-0.2252</td>\n",
              "      <td>-0.5565</td>\n",
              "      <td>0.5112</td>\n",
              "      <td>0.6727</td>\n",
              "      <td>-0.1851</td>\n",
              "      <td>2.8650</td>\n",
              "      <td>-0.2140</td>\n",
              "      <td>-0.6153</td>\n",
              "      <td>0.8362</td>\n",
              "      <td>0.5584</td>\n",
              "      <td>-0.2589</td>\n",
              "      <td>0.1292</td>\n",
              "      <td>0.0148</td>\n",
              "      <td>0.0949</td>\n",
              "      <td>-0.2182</td>\n",
              "      <td>-0.9235</td>\n",
              "      <td>0.0749</td>\n",
              "      <td>-1.5910</td>\n",
              "      <td>-0.8359</td>\n",
              "      <td>-0.9217</td>\n",
              "      <td>0.3013</td>\n",
              "      <td>0.1716</td>\n",
              "      <td>0.0880</td>\n",
              "      <td>0.1842</td>\n",
              "      <td>0.1835</td>\n",
              "      <td>0.5436</td>\n",
              "      <td>-0.0533</td>\n",
              "      <td>-0.0491</td>\n",
              "      <td>0.9543</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.3270</td>\n",
              "      <td>0.9925</td>\n",
              "      <td>1.0570</td>\n",
              "      <td>-0.3355</td>\n",
              "      <td>-0.2555</td>\n",
              "      <td>0.8219</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>-0.2942</td>\n",
              "      <td>0.2408</td>\n",
              "      <td>-0.7781</td>\n",
              "      <td>-0.0929</td>\n",
              "      <td>-0.0329</td>\n",
              "      <td>0.0781</td>\n",
              "      <td>-1.4440</td>\n",
              "      <td>-0.0921</td>\n",
              "      <td>0.3188</td>\n",
              "      <td>-1.1080</td>\n",
              "      <td>0.4895</td>\n",
              "      <td>-0.2144</td>\n",
              "      <td>1.0960</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>-1.1130</td>\n",
              "      <td>0.4286</td>\n",
              "      <td>0.4426</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>-0.3195</td>\n",
              "      <td>-0.8086</td>\n",
              "      <td>-0.9798</td>\n",
              "      <td>-0.2084</td>\n",
              "      <td>-0.1224</td>\n",
              "      <td>-0.2715</td>\n",
              "      <td>0.3689</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23811</th>\n",
              "      <td>id_fffc1c3f4</td>\n",
              "      <td>com_controle</td>\n",
              "      <td>48</td>\n",
              "      <td>D2</td>\n",
              "      <td>cacb2b860</td>\n",
              "      <td>0.3942</td>\n",
              "      <td>0.3756</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>-0.7389</td>\n",
              "      <td>0.5505</td>\n",
              "      <td>-0.0159</td>\n",
              "      <td>-0.2541</td>\n",
              "      <td>0.1745</td>\n",
              "      <td>-0.0340</td>\n",
              "      <td>0.4865</td>\n",
              "      <td>-0.1854</td>\n",
              "      <td>0.0716</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>-0.0434</td>\n",
              "      <td>0.1542</td>\n",
              "      <td>-0.2192</td>\n",
              "      <td>-0.0302</td>\n",
              "      <td>-0.4218</td>\n",
              "      <td>0.4057</td>\n",
              "      <td>-0.5372</td>\n",
              "      <td>0.1521</td>\n",
              "      <td>-0.2651</td>\n",
              "      <td>0.2310</td>\n",
              "      <td>-0.8101</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.6905</td>\n",
              "      <td>-0.3720</td>\n",
              "      <td>-1.4110</td>\n",
              "      <td>0.4516</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>-0.1949</td>\n",
              "      <td>-1.3280</td>\n",
              "      <td>-0.4276</td>\n",
              "      <td>-0.0040</td>\n",
              "      <td>-0.3086</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4144</td>\n",
              "      <td>0.5449</td>\n",
              "      <td>1.4690</td>\n",
              "      <td>-0.6142</td>\n",
              "      <td>0.6068</td>\n",
              "      <td>0.3434</td>\n",
              "      <td>0.9880</td>\n",
              "      <td>-0.0468</td>\n",
              "      <td>-0.1882</td>\n",
              "      <td>-0.0087</td>\n",
              "      <td>-0.0356</td>\n",
              "      <td>0.5718</td>\n",
              "      <td>0.4971</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.6992</td>\n",
              "      <td>0.0708</td>\n",
              "      <td>0.6169</td>\n",
              "      <td>0.2248</td>\n",
              "      <td>0.5994</td>\n",
              "      <td>0.2689</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>1.2320</td>\n",
              "      <td>0.5409</td>\n",
              "      <td>0.3755</td>\n",
              "      <td>0.7343</td>\n",
              "      <td>0.2807</td>\n",
              "      <td>0.4116</td>\n",
              "      <td>0.6422</td>\n",
              "      <td>0.2256</td>\n",
              "      <td>0.7592</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.3808</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23812</th>\n",
              "      <td>id_fffcb9e7c</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D1</td>\n",
              "      <td>8b87a7a83</td>\n",
              "      <td>0.6660</td>\n",
              "      <td>0.2324</td>\n",
              "      <td>0.4392</td>\n",
              "      <td>0.2044</td>\n",
              "      <td>0.8531</td>\n",
              "      <td>-0.0343</td>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.0463</td>\n",
              "      <td>0.4299</td>\n",
              "      <td>-0.7985</td>\n",
              "      <td>0.5742</td>\n",
              "      <td>0.1421</td>\n",
              "      <td>2.2700</td>\n",
              "      <td>0.2046</td>\n",
              "      <td>0.5363</td>\n",
              "      <td>-1.7330</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.2024</td>\n",
              "      <td>0.9865</td>\n",
              "      <td>-0.7805</td>\n",
              "      <td>0.9608</td>\n",
              "      <td>0.3440</td>\n",
              "      <td>2.7650</td>\n",
              "      <td>0.4925</td>\n",
              "      <td>0.6698</td>\n",
              "      <td>0.2374</td>\n",
              "      <td>-0.3372</td>\n",
              "      <td>0.8771</td>\n",
              "      <td>-2.6560</td>\n",
              "      <td>-0.2000</td>\n",
              "      <td>-0.2043</td>\n",
              "      <td>0.6797</td>\n",
              "      <td>-0.0248</td>\n",
              "      <td>-0.0927</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4677</td>\n",
              "      <td>-0.1184</td>\n",
              "      <td>0.4524</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.1356</td>\n",
              "      <td>-0.5801</td>\n",
              "      <td>0.0411</td>\n",
              "      <td>1.0240</td>\n",
              "      <td>1.0340</td>\n",
              "      <td>-0.0270</td>\n",
              "      <td>-0.4194</td>\n",
              "      <td>0.7403</td>\n",
              "      <td>-0.6793</td>\n",
              "      <td>-0.1423</td>\n",
              "      <td>0.7307</td>\n",
              "      <td>0.7946</td>\n",
              "      <td>-0.0650</td>\n",
              "      <td>0.9038</td>\n",
              "      <td>0.2324</td>\n",
              "      <td>0.9676</td>\n",
              "      <td>1.0940</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>0.5187</td>\n",
              "      <td>-0.1105</td>\n",
              "      <td>0.4258</td>\n",
              "      <td>-0.2012</td>\n",
              "      <td>0.1506</td>\n",
              "      <td>1.5230</td>\n",
              "      <td>0.7101</td>\n",
              "      <td>0.1732</td>\n",
              "      <td>0.7015</td>\n",
              "      <td>-0.6290</td>\n",
              "      <td>0.0740</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23813</th>\n",
              "      <td>id_ffffdd77b</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D1</td>\n",
              "      <td>972f41291</td>\n",
              "      <td>-0.8598</td>\n",
              "      <td>1.0240</td>\n",
              "      <td>-0.1361</td>\n",
              "      <td>0.7952</td>\n",
              "      <td>-0.3611</td>\n",
              "      <td>-3.6750</td>\n",
              "      <td>-1.2420</td>\n",
              "      <td>0.9146</td>\n",
              "      <td>3.0790</td>\n",
              "      <td>1.2460</td>\n",
              "      <td>1.9460</td>\n",
              "      <td>1.4370</td>\n",
              "      <td>2.9780</td>\n",
              "      <td>2.2370</td>\n",
              "      <td>-0.6818</td>\n",
              "      <td>0.6870</td>\n",
              "      <td>-1.1060</td>\n",
              "      <td>0.0182</td>\n",
              "      <td>-0.9247</td>\n",
              "      <td>-0.0738</td>\n",
              "      <td>-0.1919</td>\n",
              "      <td>-0.7722</td>\n",
              "      <td>-1.4050</td>\n",
              "      <td>-1.0050</td>\n",
              "      <td>-1.1170</td>\n",
              "      <td>-0.5293</td>\n",
              "      <td>-1.1720</td>\n",
              "      <td>-0.2885</td>\n",
              "      <td>0.1599</td>\n",
              "      <td>-0.4250</td>\n",
              "      <td>0.3591</td>\n",
              "      <td>-0.1420</td>\n",
              "      <td>-0.9530</td>\n",
              "      <td>-0.2005</td>\n",
              "      <td>-1.8340</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.1530</td>\n",
              "      <td>-1.2030</td>\n",
              "      <td>-1.1690</td>\n",
              "      <td>-4.1460</td>\n",
              "      <td>-1.2670</td>\n",
              "      <td>-1.1300</td>\n",
              "      <td>-2.4390</td>\n",
              "      <td>0.1591</td>\n",
              "      <td>-2.2490</td>\n",
              "      <td>-2.5860</td>\n",
              "      <td>-1.9520</td>\n",
              "      <td>-2.1810</td>\n",
              "      <td>-4.6690</td>\n",
              "      <td>-3.9450</td>\n",
              "      <td>-2.9560</td>\n",
              "      <td>-2.7930</td>\n",
              "      <td>-2.1560</td>\n",
              "      <td>-2.4100</td>\n",
              "      <td>-1.8190</td>\n",
              "      <td>-3.3480</td>\n",
              "      <td>-0.1414</td>\n",
              "      <td>-2.6430</td>\n",
              "      <td>-2.5810</td>\n",
              "      <td>-3.3890</td>\n",
              "      <td>-1.7450</td>\n",
              "      <td>-6.6300</td>\n",
              "      <td>-4.0950</td>\n",
              "      <td>-7.3860</td>\n",
              "      <td>-1.4160</td>\n",
              "      <td>-3.5770</td>\n",
              "      <td>-0.4775</td>\n",
              "      <td>-2.1500</td>\n",
              "      <td>-4.2520</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23814 rows × 884 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id    tratamento  tempo  ... Tempo eh 48 Tempo eh 72  ativa_2moa\n",
              "0      id_000644bb2     com_droga     24  ...           0           0           0\n",
              "1      id_000779bfc     com_droga     72  ...           0           1           0\n",
              "2      id_000a6266a     com_droga     48  ...           1           0           1\n",
              "3      id_0015fd391     com_droga     48  ...           1           0           0\n",
              "4      id_001626bd3     com_droga     72  ...           0           1           0\n",
              "...             ...           ...    ...  ...         ...         ...         ...\n",
              "23809  id_fffb1ceed     com_droga     24  ...           0           0           0\n",
              "23810  id_fffb70c0c     com_droga     24  ...           0           0           0\n",
              "23811  id_fffc1c3f4  com_controle     48  ...           1           0           0\n",
              "23812  id_fffcb9e7c     com_droga     24  ...           0           0           0\n",
              "23813  id_ffffdd77b     com_droga     72  ...           0           1           0\n",
              "\n",
              "[23814 rows x 884 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G761kp5CsOQ"
      },
      "source": [
        "Criando as variáveis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7PF6IWjCsOR"
      },
      "source": [
        "y = df_total['Eh controle']\n",
        "x_aux = df_total.drop(['id', 'tratamento', 'tempo','dose', 'composto', 'ativo_moa', 'ativa_2moa', 'Eh controle'], axis = 1)\n",
        "x = x_aux.drop(x_aux.columns[773:873], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqclyVVCCsOR"
      },
      "source": [
        "Agora iremos separar nossos conjuntos de treino e conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ179SErCsOR"
      },
      "source": [
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x,y, test_size = 0.3, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dnSQXC5CsOR"
      },
      "source": [
        "Como antes, vamos criar também um dataframe com informações sumarizadas das performaces de cada modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-8k2GDYCsOS"
      },
      "source": [
        "lista_modelo = []\n",
        "lista_score = []\n",
        "lista_precision0 = [] \n",
        "lista_precision1 = []\n",
        "lista_recall0 = []\n",
        "lista_recall1 = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK4FkyCECsOS"
      },
      "source": [
        "### Regressão Logistica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTuMta-OCsOS",
        "outputId": "733384df-608b-4f35-cfef-3df19db22cee"
      },
      "source": [
        "modelo = LogisticRegression()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  95.0594821553534 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Osx6OoACsOT",
        "outputId": "f09217f8-1790-4bf2-8ada-1de9097e0273"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6417  168]\n",
            " [ 185  375]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJV95VloCsOT",
        "outputId": "5ed07ae1-9b18-42e9-bf9f-c013519863c4"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      6585\n",
            "           1       0.69      0.67      0.68       560\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.83      0.82      0.83      7145\n",
            "weighted avg       0.95      0.95      0.95      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTtfiyfOCsOT"
      },
      "source": [
        "### DecisionTreeClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUFlNOEfCsOU",
        "outputId": "893f7ae2-5698-4e40-9c93-ad4a06b57825"
      },
      "source": [
        "modelo = DecisionTreeClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  88.91532540237928 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN3mWeCQCsOU",
        "outputId": "36a33f2c-e80c-4981-83aa-612fb835546d"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6169  416]\n",
            " [ 376  184]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyUtOB2TCsOU",
        "outputId": "07c5b959-6891-49c5-d322-bac11ca62603"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      6585\n",
            "           1       0.31      0.33      0.32       560\n",
            "\n",
            "    accuracy                           0.89      7145\n",
            "   macro avg       0.62      0.63      0.63      7145\n",
            "weighted avg       0.89      0.89      0.89      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU_acEsNCsOU"
      },
      "source": [
        "### RandomFlorestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBrVYuLfCsOU",
        "outputId": "c592a749-433d-4aa8-81ec-f3d4b6cac17e"
      },
      "source": [
        "modelo = RandomForestClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  92.9741077676697 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX_O9hDNCsOV",
        "outputId": "746b1efa-17c6-4be4-85d0-9b08bbfbc216"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6577    8]\n",
            " [ 494   66]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpGJWJiaCsOV",
        "outputId": "9103d69c-dd6f-4558-cf82-318da6e51463"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      6585\n",
            "           1       0.89      0.12      0.21       560\n",
            "\n",
            "    accuracy                           0.93      7145\n",
            "   macro avg       0.91      0.56      0.59      7145\n",
            "weighted avg       0.93      0.93      0.90      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68kW-cjVCsOV"
      },
      "source": [
        "### LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-xGWer5CsOV",
        "outputId": "bfa2a8f7-72fd-40d7-a1ad-b71b56cb1be0"
      },
      "source": [
        "modelo = LGBMClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  95.0594821553534 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q6sMjWJCsOV",
        "outputId": "b22beebe-850f-438e-da8b-70a67687276b"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6518   67]\n",
            " [ 286  274]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d-y3gnpCsOV",
        "outputId": "4b532ebe-5545-42ab-f37d-234f9857a7dc"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      6585\n",
            "           1       0.80      0.49      0.61       560\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.88      0.74      0.79      7145\n",
            "weighted avg       0.95      0.95      0.94      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVt8PLhkCsOW"
      },
      "source": [
        "### XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9QFCaawCsOW",
        "outputId": "553da124-f566-4b89-e2ba-31ffbe520e4f"
      },
      "source": [
        "modelo = XGBClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  94.61161651504548 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9fVxO0UCsOW",
        "outputId": "ea0ea5c5-ab8d-4f29-a49d-ea00aaad8697"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6517   68]\n",
            " [ 317  243]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7wzerRJCsOW",
        "outputId": "f0635b57-cefe-4b3a-959b-b294aa40d7c6"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      6585\n",
            "           1       0.78      0.43      0.56       560\n",
            "\n",
            "    accuracy                           0.95      7145\n",
            "   macro avg       0.87      0.71      0.76      7145\n",
            "weighted avg       0.94      0.95      0.94      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en56jaZRCsOW"
      },
      "source": [
        "### GradientBoostingClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8fRC4qECsOW",
        "outputId": "d132a967-1d53-43ab-e315-9cd3297019f4"
      },
      "source": [
        "modelo = GradientBoostingClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  94.44366689993002 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um680Jh_CsOX",
        "outputId": "b721474f-27f2-4ca0-df88-5bce9d3d1be9"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6500   85]\n",
            " [ 312  248]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsLr67KvCsOX",
        "outputId": "1ceed4ca-975f-40e6-94a8-8b7bdde98a7c"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      6585\n",
            "           1       0.74      0.44      0.56       560\n",
            "\n",
            "    accuracy                           0.94      7145\n",
            "   macro avg       0.85      0.71      0.76      7145\n",
            "weighted avg       0.94      0.94      0.94      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX5UkwVWCsOZ"
      },
      "source": [
        "### KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB_jtlgfCsOZ",
        "outputId": "ea992f5f-c2d2-4cb8-caf1-2c9ddc599a64"
      },
      "source": [
        "modelo = KNeighborsClassifier()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  93.65990202939119 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U2h5QetCsOZ",
        "outputId": "16afa669-379e-45c4-9104-61230f333f8d"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6519   66]\n",
            " [ 387  173]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lFRIA_SCsOZ",
        "outputId": "52a7d644-bafd-4d9e-de81-e36887467289"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97      6585\n",
            "           1       0.72      0.31      0.43       560\n",
            "\n",
            "    accuracy                           0.94      7145\n",
            "   macro avg       0.83      0.65      0.70      7145\n",
            "weighted avg       0.93      0.94      0.92      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHoCTf2qCsOa"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peKdGKjfCsOa",
        "outputId": "7dea029b-6c83-462b-a7ff-fea46ca614f8"
      },
      "source": [
        "modelo = SVC()\n",
        "lista_modelo.append(str(modelo).split('(')[0])\n",
        "modelo.fit(x_treino,y_treino)\n",
        "resultado = modelo.score(x_teste,y_teste)\n",
        "lista_score.append(resultado)\n",
        "print('Score = ', resultado*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score =  95.52134359692093 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEKqtgi_CsOa",
        "outputId": "1d190e46-9161-48d4-fca6-b0041b1415cc"
      },
      "source": [
        "cm = confusion_matrix(y_teste, modelo.predict(x_teste))\n",
        "lista_precision0.append(cm[0][0]/(cm[0][0]+cm[1][0]))\n",
        "lista_precision1.append(cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "lista_recall0.append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
        "lista_recall1.append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6516   69]\n",
            " [ 251  309]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHAXw6ylCsOa",
        "outputId": "ef12d5c5-944c-4a32-d3f4-be6b2a4b9746"
      },
      "source": [
        "print(classification_report(y_teste, modelo.predict(x_teste)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98      6585\n",
            "           1       0.82      0.55      0.66       560\n",
            "\n",
            "    accuracy                           0.96      7145\n",
            "   macro avg       0.89      0.77      0.82      7145\n",
            "weighted avg       0.95      0.96      0.95      7145\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arsUclu7CsOa"
      },
      "source": [
        "### Resumo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "EzhEcPOsCsOa",
        "outputId": "acfeb2cd-1c2f-4f61-e2bb-c025a0278087"
      },
      "source": [
        "Tabela_Performace_Modelos = pd.DataFrame()\n",
        "Tabela_Performace_Modelos['Modelo'] = lista_modelo\n",
        "Tabela_Performace_Modelos['Score'] = lista_score\n",
        "Tabela_Performace_Modelos['precision-0'] = lista_precision0\n",
        "Tabela_Performace_Modelos['precision-1'] = lista_precision1\n",
        "Tabela_Performace_Modelos['recall-0'] = lista_recall0\n",
        "Tabela_Performace_Modelos['recall-1'] = lista_recall1\n",
        "\n",
        "Tabela_Comparação_Modelos_Problema4 = Tabela_Performace_Modelos\n",
        "Tabela_Comparação_Modelos_Problema4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Score</th>\n",
              "      <th>precision-0</th>\n",
              "      <th>precision-1</th>\n",
              "      <th>recall-0</th>\n",
              "      <th>recall-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.950595</td>\n",
              "      <td>0.971978</td>\n",
              "      <td>0.690608</td>\n",
              "      <td>0.974487</td>\n",
              "      <td>0.669643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.889153</td>\n",
              "      <td>0.942552</td>\n",
              "      <td>0.306667</td>\n",
              "      <td>0.936826</td>\n",
              "      <td>0.328571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.929741</td>\n",
              "      <td>0.930137</td>\n",
              "      <td>0.891892</td>\n",
              "      <td>0.998785</td>\n",
              "      <td>0.117857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBMClassifier</td>\n",
              "      <td>0.950595</td>\n",
              "      <td>0.957966</td>\n",
              "      <td>0.803519</td>\n",
              "      <td>0.989825</td>\n",
              "      <td>0.489286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.946116</td>\n",
              "      <td>0.953614</td>\n",
              "      <td>0.781350</td>\n",
              "      <td>0.989674</td>\n",
              "      <td>0.433929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.944437</td>\n",
              "      <td>0.954198</td>\n",
              "      <td>0.744745</td>\n",
              "      <td>0.987092</td>\n",
              "      <td>0.442857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.936599</td>\n",
              "      <td>0.943962</td>\n",
              "      <td>0.723849</td>\n",
              "      <td>0.989977</td>\n",
              "      <td>0.308929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.955213</td>\n",
              "      <td>0.962908</td>\n",
              "      <td>0.817460</td>\n",
              "      <td>0.989522</td>\n",
              "      <td>0.551786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Modelo     Score  ...  recall-0  recall-1\n",
              "0          LogisticRegression  0.950595  ...  0.974487  0.669643\n",
              "1      DecisionTreeClassifier  0.889153  ...  0.936826  0.328571\n",
              "2      RandomForestClassifier  0.929741  ...  0.998785  0.117857\n",
              "3              LGBMClassifier  0.950595  ...  0.989825  0.489286\n",
              "4               XGBClassifier  0.946116  ...  0.989674  0.433929\n",
              "5  GradientBoostingClassifier  0.944437  ...  0.987092  0.442857\n",
              "6        KNeighborsClassifier  0.936599  ...  0.989977  0.308929\n",
              "7                         SVC  0.955213  ...  0.989522  0.551786\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GXN3gZLOBri"
      },
      "source": [
        "Estudando a tabela com o resumo das análises, percebemos que as acurácias estão altas, porém as outras méticas estão dispersas. Em geral, os modelos tem uma alta precisão para negativos, o que é razoável de se pensar, pois temos muito mais amostras que não são do grupo de controle. A precisão para positovos está boa, em geral (com excessão do decision tree), porém a revocação para positivos está bem baixa. Isso significa que há muitos do grupo de controle que estão sendo classficados como não sendo do grupo de controle. \n",
        "Minha conclusão é que os modelos tem desempenho mediano. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TjfvfINNXQH"
      },
      "source": [
        "## Outros problemas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln-kCgQrNar6"
      },
      "source": [
        "Gostaria de sugerir outros problemas que podem ser atacados utilizando as mesmas téncinas de machine learning. Não os resolvo aqui por questão de tempo. Porém, me comprometo a estudar esses problemas nos próximos dias e então adicionar um outro arquivo no repositório, com as novas análises. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2PNZrQUN1m1"
      },
      "source": [
        "### Prever se um composto ativa dois MOAs específicos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4ThxuSQPIOH"
      },
      "source": [
        "Como a quantidade total de positivos será muito baixa (comparado com o total), espero uma acurácia alta, porém uma tendência à ter uma precisão baixa para positivos. \n",
        "Pretendo também testar como os modelos se saem com MOAs com alta correlação e MOAs com baixa correlação. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUh42BANPoEo"
      },
      "source": [
        "### Prever se um composto ativa um MOA específico, mas não ativa outro MOA específico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AI-J1a0P0tv"
      },
      "source": [
        "Aqui espero um cenário similar ao do Problema 3, e portanto resultados similares. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMqvFzuWQEXh"
      },
      "source": [
        "### Recuperar uma expressão gênica a partir dos MOAs ativados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W9dwRUUQSqn"
      },
      "source": [
        "Aqui estou propondo meio que o problema inverso do que estávamos fazendo. Não sei se faz sentido biológico ou não querer saber isso, mas achei interessante.\n",
        "Obviamente, vou me concentrar em apenas uma expressão gênica (e.g., g0). \n",
        "Outro ponto a observar é que a natureza do problema é distinta. Até o momento, trabalhamos apenas com problemas de classficação binária. Este é um problema de regressão. Os modelos serão outros. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC1Yk1UEQ-cj"
      },
      "source": [
        "### Recuperar o composto a partir das expressões gênicas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2nRoPosRHGG"
      },
      "source": [
        "Agora trata-se um um problema de classficiação multi classe. Provavelmente será mais fácil se eu me restringir àqueles nove compostos mais frequentes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL4BFpcsRYhl"
      },
      "source": [
        "### Recuperar o composto a partir dos MOAs ativados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO-4zxTJRiPD"
      },
      "source": [
        "Similar ao problema anterior, com a vantagem de que penso ser mais fácil de se obter os dados em laboratório.\n",
        "(quero dizer que penso que seja mais fácil verificar se um MOA foi ativado do que calcular a expressão gênica)"
      ]
    }
  ]
}